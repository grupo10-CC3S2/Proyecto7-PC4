commit f6a5bf9f96cc9c016b68eff1dca16777d51f55ae
Author: Jesus Diego Osorio Tello <130506742+JesusOsorio-19@users.noreply.github.com>
Date:   Sun Jun 22 13:30:04 2025 -0500

    Initial commit
---
 README.md | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/README.md b/README.md
new file mode 100644
index 0000000..2dd6bca
--- /dev/null
+++ b/README.md
@@ -0,0 +1,2 @@
+# Proyecto7-PC4
+# Observabilidad de clúster Kubernetes local (mini-monitoring)

commit a7be7d56bd7746479d6e3ce888651e12f69c9711
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Wed Jun 25 21:40:43 2025 -0500

    feat(dockerfile): agrega dockerfile para app de flask
---
 app/Dockerfile | 6 ++++++
 1 file changed, 6 insertions(+)

diff --git a/app/Dockerfile b/app/Dockerfile
new file mode 100644
index 0000000..2b6457b
--- /dev/null
+++ b/app/Dockerfile
@@ -0,0 +1,6 @@
+FROM python:3.12
+ENV PYTHONUNBUFFERED 1
+COPY . /app
+WORKDIR /app
+RUN pip install flask tzdata
+CMD python3 server.py
\ No newline at end of file

commit fb0da48c84dd0b00f4b7fc15a8b0e3631deb0e40
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Wed Jun 25 21:41:01 2025 -0500

    feat(py): agrega app inicial que es un servidor en flask
---
 app/server.py | 21 +++++++++++++++++++++
 1 file changed, 21 insertions(+)

diff --git a/app/server.py b/app/server.py
new file mode 100644
index 0000000..c202fec
--- /dev/null
+++ b/app/server.py
@@ -0,0 +1,21 @@
+from flask import Flask, Response
+from datetime import datetime, timezone
+from zoneinfo import ZoneInfo
+
+app = Flask(__name__)
+
+LIMA_TZ = ZoneInfo("America/Lima")
+
+
+@app.route("/")
+def get_current_time():
+    now = datetime.now(timezone.utc)
+    now_lima = now.astimezone(LIMA_TZ)
+
+    response_string = now.strftime("La hora es %I:%M %p, UTC.\n")
+    response_string += now_lima.strftime("La hora en Lima es %I:%M %p.\n")
+    return Response(response_string, mimetype='text/plain')
+
+
+if __name__ == "__main__":
+    app.run(host='0.0.0.0', port=80)
\ No newline at end of file

commit 15034c7bc69c09a3fc3697bac29a6e0ce48fa50b
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Wed Jun 25 21:41:32 2025 -0500

    feat(yaml): agrega manifest inicial para desplegar app
---
 k8s/deploy.yaml | 18 ++++++++++++++++++
 1 file changed, 18 insertions(+)

diff --git a/k8s/deploy.yaml b/k8s/deploy.yaml
new file mode 100644
index 0000000..31585a8
--- /dev/null
+++ b/k8s/deploy.yaml
@@ -0,0 +1,18 @@
+apiVersion: apps/v1
+kind: Deployment
+metadata:
+  name: timeserver
+spec:
+  replicas: 3
+  selector:
+    matchLabels:
+      pod: timeserver-pod
+  template:
+    metadata:
+      labels:
+        pod: timeserver-pod
+    spec:
+      containers:
+      - name: timeserver-container
+        image: timeserver:latest
+        imagePullPolicy: Never
\ No newline at end of file

commit 34706e1413c2eae84aac06d4c27a80761b33fab7
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Wed Jun 25 21:42:44 2025 -0500

    feat(yaml): agrega manifest inicial de servicio
---
 k8s/service.yaml | 12 ++++++++++++
 1 file changed, 12 insertions(+)

diff --git a/k8s/service.yaml b/k8s/service.yaml
new file mode 100644
index 0000000..642f9ff
--- /dev/null
+++ b/k8s/service.yaml
@@ -0,0 +1,12 @@
+apiVersion: v1
+kind: Service
+metadata:
+  name: timeserver
+spec:
+  selector:
+    pod: timeserver-pod
+  ports:
+  - port: 80
+    targetPort: 80
+    protocol: TCP
+  type: LoadBalancer
\ No newline at end of file

commit 6c8c003503c17b723a0d0133826a28ec3394be4d
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Wed Jun 25 21:42:55 2025 -0500

    docs(md): agrega README inicial
---
 README.md | 57 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 57 insertions(+)

diff --git a/README.md b/README.md
index 2dd6bca..b774772 100644
--- a/README.md
+++ b/README.md
@@ -1,2 +1,59 @@
 # Proyecto7-PC4
 # Observabilidad de clúster Kubernetes local (mini-monitoring)
+# test-repo-pc4
+# Proyecto 7: Observabilidad de clúster Kubernetes local (mini-monitoring)
+
+## Integrantes:
+
+- Christian Luna
+- Diego Osorio
+- Alex Vega
+
+## Setup
+
+1. Construir la imagen Docker local:
+   ```sh
+   docker build -t timeserver:latest app
+   ```
+2. Verificar que Kubernetes esta activado:
+   ```sh
+   kubectl cluster-info
+   ```
+    Debe decir:
+    ```sh
+    Kubernetes control plane is running at https://kubernetes.docker.internal:6443
+    CoreDNS is running at https://kubernetes.docker.internal:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
+
+    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
+    ```
+
+3. Desplegar pods:
+   ```sh
+   kubectl apply -f k8s/
+   ```
+4. Comprobar que Pods estan corriendo:
+   ```sh
+   kubectl get pods
+   ```
+5. Ir a un navegador y abrir:
+    ```sh
+    http://localhost:80
+   ```
+Se obtendra el tiempo actual en timezone UTC y Lima.
+
+
+## Limpieza
+
+Para borrar todo lo creado y liberar recursos:
+
+1. Eliminar recursos en Kubernetes:
+   ```sh
+   kubectl delete -f k8s/
+   ```
+
+2. Eliminar la imagen (esperar unos segundos):
+   ```sh
+   docker image rm timeserver
+   ```
+
+`linea de prueba`
\ No newline at end of file

commit eec11a91b6e42417d7847d9485ec81ecdda470cb
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 22:44:47 2025 -0500

    docs(README): Añade documentación con explicación de los hooks e instalación de los hooks
---
 hooks/README.md | 189 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 189 insertions(+)

diff --git a/hooks/README.md b/hooks/README.md
new file mode 100644
index 0000000..3ef360d
--- /dev/null
+++ b/hooks/README.md
@@ -0,0 +1,189 @@
+# Documentación de funciones de los hooks 
+
+## commit-msg
+
+Este hook lo que hace va a ser que al momento de escribir el commit respectivo y ejecutar, en la línea 3 se guarda la ruta temporal del mensaje del commit en la variable commit_msg_file
+```bash
+commit_msg_file=$1
+```
+Luego en la siguiente línea solo se guarda la ejecución del comando cat para la ruta que se guardó anteriormente
+```bash
+commit_msg=$(cat "$commit_msg_file")
+```
+
+En la variable **validation** se guarda mediante expresiones regulares, los requisitos que debe de tener el mensaje de commit:
+```bash
+validation="^(feat|fix|docs|test)(\([a-z0-9\-]+\))?: .{1,}"
+```
+Explicación de la expresión regular\
+- **(feat|fix|docs|test)**: Verifica que el comienzo del mensaje sea "feat, fix, docs o test" según como lo indica la rúbrica la cuál pertenece a la convención de commits
+- **(\([a-z0-9\-]+\))?:**: Esto indicará que luego de la primera verificación, el mensaje puede incluir mensaje entre paréntesis y terminando por el símbolo `:` y además un espacio adicional luego de los dos puntos ` ` como por ejemplo `feat(tf): <msg_commit>`
+- **.{1,}**: La última restricción, verifica que al menos haya un carácter en la descripción, es decir, el mensaje del commit no puede estar vacío
+
+La última parte es solo una condicional de bash, que verificará si **commit_msg** el cuál es el mensaje del commit, siga las verificaciones dadas en la variable **validation**, en caso no cumpla, nos dará como respouesta que nuestro mensaje de commit no cumple con la convención de commits
+```bash
+if echo "$commit_msg" | grep -qE "$validation"; then
+  exit 0
+else
+  echo "El mensaje de commit no sigue la Convención de Commits." 
+  echo "Ejemplo de mensaje: 'feat(tf-module):', 'fix(hooks)', 'docs(readme)' o 'test(py)'"
+  exit 1
+fi
+```
+### Ejemplo de ejecución
+> Agregamos de manera normal los cambios hechos para que estén listos para el commit.
+> Haremos el primer commit que tenga el mensaje `Add README.md for documentation` y como no cumple la convención, nos avisará ello.
+```bash
+git commit -m "Add README.md for documentation"
+El mensaje de commit no sigue la Convención de Commits.
+Ejemplo de mensaje: 'feat(tf-module):', 'fix(hooks)', 'docs(readme)' o 'test(py)'
+```
+> Notamos que como se esperaba, nos avisa que el mensaje de commit no cumple con la convención de commits
+> Comiteamos nuevamente pero ahora con el mensaje `docs(readme): Add README.md for documentation` el cuál ya respeta la convención y nos tendría que aceptar el commit sin problemas:
+```bash
+git commit -m "docs(readme): Add README.md for documentation"
+[master 4e9b678] docs(readme): Add README.md for documentation
+ 1 file changed, 25 insertions(+)
+ create mode 100644 hooks/README.md
+```
+
+Y de esta manera notamos que nuestro hook commit-msg nos permitirá realizar commits que cumplan la convención de commits
+
+## pre-commit
+
+Al iniciar el hook se buscan los archivos que estan siendo commiteados con `git diff` y se filtran los archivos `.py` (y un patron regex) con grep.
+
+```bash
+PY_FILES=$(git diff --cached --name-only | grep '\.py$')
+
+echo "$PY_FILES"
+```
+
+Si no hay archivos python, no se realizan mas acciones se termina con un output de OK (0).
+
+```bash
+if [ -z "$PY_FILES" ]; then
+    echo "Sin archivos python para formateo o linting."
+    exit 0
+fi
+```
+
+En cambio si hay archivos `.py`, se realiza un bucle con los archivos python y se realiza un formateo con black y chequeo de lint con flake8, si hay un error en flake8 este genera un codigo y mensaje error y con un OR ( || ) se genera un output de error (1) en bash
+
+```bash
+for file in $PY_FILES; do
+    black "$file"
+    flake8 "$file" || exit 1    # al ultimo para ver si hay errores que no son solucionados por black
+done
+
+exit 0
+```
+
+Con este git hook se realiza formateo con black y chequeo de errors de lint con flake8 solo en archivos python, de esta manera los commits subidos al repositorio remoto seran limpios y los errores de lint disminuiran.
+
+### Ejemplo de ejecución
+
+> Se agrega un archivo python al staging area de git, luego se escribe el mensaje de commit
+
+```bash
+git add src/main.py
+git commit -m "feat(py): 'Agrega archivo python inicial'"
+```
+
+> Cuando se realize el comando de commit se mostraran mensajes con los archivos python encontrados, y si se realizan formateos asi como los mensajes de errores de lint.
+
+```bash
+src/main.py
+All done! 
+1 file left unchanged.
+src/main.py:17:80: E501 line too long (96 > 79 characters)
+```
+
+En este caso se realizo un formateo con black y flake8 muestra que la linea es muy larga (> 79 caracteres), por lo que el hook formateara el archivo y saldra del area de staging evitando el commit incorrecto. Cuando se solucione el error se mostrara el siguiente mensaje.
+
+```bash
+src/main.py
+All done!
+1 file left unchanged.
+[master fdf666e] "feat(py): 'Agrega archivo python inicial'"
+ 1 file changed, 2 insertions(+), 1 deletion(-)
+ ```
+
+ Confirmando que se realizo el commit sin errores de lint y formateo.
+
+## pre-push
+
+Este hook va validar 3 acciones antes de realizar un push. 
+
+- El primero será que no permitirá un `git push origin main`.
+Inicialmente el script obtendrá el nombre de la rama actual y mostrará el nombre de la rama.
+  ```bash
+  current_branch=$(git symbolic-ref --short HEAD)
+  echo "Rama actual: $current_branch"
+  ```
+
+  Entonces, si la rama actual es `main` nuestra mensajes de error y retorna con código 1.
+  ```bash
+  if [ "$current_branch" = "main" ]; then
+      echo "Push directo a rama principal no permitido."
+      echo "Protección local, complementa reglas de GitHub."
+      exit 1
+  fi
+  ```
+
+- El segunddo es para ejecutar los tests que tengamos. Verifica si existe el directorio `tests` y si contiene archivos `Python`. Si hay tests, los ejecuta usando pytest con modo verbose (-v), si los tests fallan muestra mensaje de error y sale con código 1 y si los tests pasan muestra mensaje de éxito
+  ```bash
+  if [ -d "tests" ] && [ -n "$(find tests -name '*.py' -print -quit)" ]; then
+      echo "Ejecutando tests"
+      python -m pytest tests/ -v
+      if [ $? -ne 0 ]; then
+          echo "Tests fallaron. Fix antes de push."
+          exit 1
+      fi
+      echo "Tests pasaron."
+  fi
+  ```
+
+- Y por último valida si hay cambios pendientes o no. Verifica si hay diferencias entre el último commit y el anterior y si no hay cambios, muestra un mensaje informativo. 
+  ```bash
+  if git diff --quiet HEAD~1 HEAD 2>/dev/null; then
+    echo "No hay cambios para pushear."
+  fi
+  ```
+
+### Ejemplo de ejecución
+Si hacemos push desde la rama `main`
+```bash
+git add .
+git commit -m "feat(hooks): Se añade hooks pre-commit, pre-push, commit-msg"
+git push origin main
+```
+
+Cuando se haga el push nos botará mensajes de error.
+```bash
+Ejecutando validaciones pre-push...
+Rama actual: main
+Push directo a la rama principal no permitido.
+Protección local, complementa reglas de GitHub.
+error: failed to push some refs to 'https://github.com/grupo10-CC3S2/Proyecto7-PC4.git'
+```
+
+Si estamos en otra rama distinta a main, tenemos la carpeta tests y no tenemos cambios pendientes entre commits.
+```bash
+Ejecutando validaciones pre-push...
+Rama actual: feature/...
+Ejecutando tests
+.
+.
+.
+Test pasaron.
+Validaciones pre-push completadas. Push puede continuar.
+``` 
+
+ ## Pasos para instalar los hooks
+ 
+ 1. Creamos el directorio hooks, el cual contendrá los archivos `pre-commit`, `commit-msg` y `pre-push`.
+
+ 2. En el directorio raiz implementamos un script `install_hooks.sh` que optimizará el uso de nuestros hooks.
+
+ 3. Ejecutar el comando `chmod +x install_hooks.sh` para convertir el archivo en ejecutable y por último lo ejecutamos `./install_hooks.sh`.
\ No newline at end of file

commit 2d273ce022c24c9c4382150404e5256583b1860a
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 22:46:00 2025 -0500

    feat(hook): Añade hook commit-msg para validación de archivos python siguiendo convenciones
---
 hooks/commit-msg | 14 ++++++++++++++
 1 file changed, 14 insertions(+)

diff --git a/hooks/commit-msg b/hooks/commit-msg
new file mode 100644
index 0000000..f1d462f
--- /dev/null
+++ b/hooks/commit-msg
@@ -0,0 +1,14 @@
+#!/bin/sh
+
+commit_msg_file=$1
+commit_msg=$(cat "$commit_msg_file")
+
+validation="^(feat|fix|docs|test)(\([a-z0-9\-]+\))?: .{1,}"      
+
+if echo "$commit_msg" | grep -qE "$validation"; then
+  exit 0
+else
+  echo "El mensaje de commit no sigue la Convención de Commits." 
+  echo "Ejemplo de mensaje: 'feat(tf-module):', 'fix(hooks)', 'docs(readme)' o 'test(py)'"
+  exit 1
+fi
\ No newline at end of file

commit 5a8d9bdf3a14155477aa81f451f847119f9adf67
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 22:47:14 2025 -0500

    feat(hook): Añade pre-commit para validación de archivos python
---
 hooks/pre-commit | 17 +++++++++++++++++
 1 file changed, 17 insertions(+)

diff --git a/hooks/pre-commit b/hooks/pre-commit
new file mode 100644
index 0000000..e373afd
--- /dev/null
+++ b/hooks/pre-commit
@@ -0,0 +1,17 @@
+#!/bin/sh
+
+PY_FILES=$(git diff --cached --name-only | grep '\.py$')
+
+echo "$PY_FILES"
+
+if [ -z "$PY_FILES" ]; then
+    echo "Sin archivos python para formateo o linting."
+    exit 0
+fi
+
+for file in $PY_FILES; do
+    black "$file"
+    flake8 "$file" || exit 1    # al ultimo para ver si hay errores que no son solucionados por black
+done
+
+exit 0
\ No newline at end of file

commit 7f3bf76f7b496773800912403739a566a6ab7056
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 22:49:31 2025 -0500

    feat(hook): Añade pre-push que impide el push desde la rama main, ejecuta los test y valida que no haya cambios pendientes entre commits
---
 hooks/pre-push | 29 +++++++++++++++++++++++++++++
 1 file changed, 29 insertions(+)

diff --git a/hooks/pre-push b/hooks/pre-push
new file mode 100644
index 0000000..54037e6
--- /dev/null
+++ b/hooks/pre-push
@@ -0,0 +1,29 @@
+#!/bin/sh
+
+echo "Ejecutando validaciones pre-push..."
+
+current_branch=$(git symbolic-ref --short HEAD)
+echo "Rama actual: $current_branch"
+
+if [ "$current_branch" = "main" ]; then
+    echo "Push directo a rama principal no permitido."
+    echo "Protección local, complementa reglas de GitHub."
+    exit 1
+fi
+
+if [ -d "tests" ] && [ -n "$(find tests -name '*.py' -print -quit)" ]; then
+    echo "Ejecutando tests"
+    python -m pytest tests/ -v
+    if [ $? -ne 0 ]; then
+        echo "Tests fallaron. Fix antes de push."
+        exit 1
+    fi
+    echo "Tests pasaron."
+fi
+
+if git diff --quiet HEAD~1 HEAD 2>/dev/null; then
+    echo "No hay cambios para pushear."
+fi
+
+echo "Validaciones pre-push completadas. Push puede continuar."
+exit 0

commit 1bc1273ff757a5537c78631e974d19454ec8b9dc
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 22:51:56 2025 -0500

    feat(hook): Añade install que facilita la instalación de los hooks
---
 install_hooks.sh | 13 +++++++++++++
 1 file changed, 13 insertions(+)

diff --git a/install_hooks.sh b/install_hooks.sh
new file mode 100644
index 0000000..2c56f3d
--- /dev/null
+++ b/install_hooks.sh
@@ -0,0 +1,13 @@
+echo "Instalando hooks"
+
+cp hooks/commit-msg .git/hooks/
+cp hooks/pre-commit .git/hooks/
+cp hooks/pre-push .git/hooks/
+
+chmod +x .git/hooks/commit-msg
+chmod +x .git/hooks/pre-commit
+chmod +x .git/hooks/pre-push
+
+echo "Hooks instalados correctamente"
+echo ""
+

commit 4446fa031c40c4977a93ed6f94b3472744c306fd
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 22:57:11 2025 -0500

    feat(bandit): Añade archivo para detectar vulnerabilidades de seguridad en código python
---
 .bandit | 6 ++++++
 1 file changed, 6 insertions(+)

diff --git a/.bandit b/.bandit
new file mode 100644
index 0000000..450852e
--- /dev/null
+++ b/.bandit
@@ -0,0 +1,6 @@
+[bandit]
+exclude = .git,.pytest_cache,.venv,venv,.terraform,tests
+skips = B101,B311
+severity-level = MEDIUM
+confidence-level = MEDIUM
+recursive = True

commit 87750c58cf7f119ad0d0fb8c89b584d5b7d62f58
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 22:57:48 2025 -0500

    feat(flake): Añade archivo para análisis de calidad de código python
---
 .flake8 | 16 ++++++++++++++++
 1 file changed, 16 insertions(+)

diff --git a/.flake8 b/.flake8
new file mode 100644
index 0000000..d6b6fde
--- /dev/null
+++ b/.flake8
@@ -0,0 +1,16 @@
+[flake8]
+max-line-length = 120
+exclude = 
+    .git,
+    __pycache__,
+    build,
+    dist,
+    .venv,
+    venv,
+    .terraform
+
+ignore = 
+    E203,
+    W503,
+    E501,
+    F401 

commit 7ed820f9a91d8b5ed0f9c4035528e08c40ebfcbf
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 23:00:03 2025 -0500

    feat(ignore): Añade documentación con archivos a ignorar al hacer push a nuestro repositorio remoto
---
 .gitignore | 14 ++++++++++++++
 1 file changed, 14 insertions(+)

diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..ceb5ae8
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,14 @@
+__pycache__/
+
+htmlcov/
+.coverage
+.coverage.*
+coverage.xml
+.pytest_cache/
+
+.env
+.venv
+env/
+venv/
+
+

commit 611734cc46b19625421e6d5798ca3b00696022e6
Author: Diego <jesustello192002@gmail.com>
Date:   Wed Jun 25 23:00:39 2025 -0500

    feat(dependencias): Añade archivo con dependencias necesarias
---
 requirements.txt | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/requirements.txt b/requirements.txt
new file mode 100644
index 0000000..c4c6180
--- /dev/null
+++ b/requirements.txt
@@ -0,0 +1,8 @@
+black
+flake8
+bandit
+pytest
+pytest-cov
+pytest-mock
+pytest-html
+kubernetes
\ No newline at end of file

commit 9acaee10c63c67247f287e7b0c369f2eb8b21eb5
Merge: f6a5bf9 1bc1273
Author: Alex Vega <91773368+axvg@users.noreply.github.com>
Date:   Wed Jun 25 23:13:17 2025 -0500

    Merge pull request #15 from grupo10-CC3S2/feature/git-hooks
    
    Scripts de hooks

commit 3ef52e878bd843e77f00886c329d08312ddb72ea
Merge: 9acaee1 611734c
Author: Christian Luna Jaramillo <65150753+Chriss5-2@users.noreply.github.com>
Date:   Wed Jun 25 23:13:31 2025 -0500

    Merge pull request #14 from grupo10-CC3S2/feature/conf-iniciales
    
    Archivos de configuración inicial

commit 310fdc0f0035c0ccd0e148caafba8ab585e92a0e
Merge: 3ef52e8 6c8c003
Author: Jesus Diego Osorio Tello <130506742+JesusOsorio-19@users.noreply.github.com>
Date:   Wed Jun 25 23:14:13 2025 -0500

    Merge pull request from feature/docker-k8s-iniciales
    
    Feature/docker k8s iniciales

commit b7431f550b097b92d87458c8e6d5a92d24e5bb8a
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Wed Jun 25 23:28:01 2025 -0500

    fix(md): remueve lineas
---
 README.md | 6 +-----
 1 file changed, 1 insertion(+), 5 deletions(-)

diff --git a/README.md b/README.md
index b774772..8dfb58f 100644
--- a/README.md
+++ b/README.md
@@ -1,7 +1,5 @@
 # Proyecto7-PC4
 # Observabilidad de clúster Kubernetes local (mini-monitoring)
-# test-repo-pc4
-# Proyecto 7: Observabilidad de clúster Kubernetes local (mini-monitoring)
 
 ## Integrantes:
 
@@ -54,6 +52,4 @@ Para borrar todo lo creado y liberar recursos:
 2. Eliminar la imagen (esperar unos segundos):
    ```sh
    docker image rm timeserver
-   ```
-
-`linea de prueba`
\ No newline at end of file
+   ```
\ No newline at end of file

commit 4d244dc7ffc0aef1a6bcf1c8a453d91125eb8516
Merge: 310fdc0 b7431f5
Author: Alex Vega <91773368+axvg@users.noreply.github.com>
Date:   Wed Jun 25 23:28:37 2025 -0500

    Merge pull request #16 from grupo10-CC3S2/hotfix/fix-readme-1
    
    fix(md): remueve lineas

commit d1db1bb2acbd4dceba7ba75216a741339bc50c9b
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Wed Jun 25 23:34:19 2025 -0500

    feat(scripts): Implementando script log_collector.py y log_collector.sh para la recolección de logs y eventos de los pods
---
 scripts/log_collector.py | 74 ++++++++++++++++++++++++++++++++++++++++++++++++
 scripts/log_collector.sh | 22 ++++++++++++++
 2 files changed, 96 insertions(+)

diff --git a/scripts/log_collector.py b/scripts/log_collector.py
new file mode 100644
index 0000000..de5609e
--- /dev/null
+++ b/scripts/log_collector.py
@@ -0,0 +1,74 @@
+import os
+import subprocess
+import sys
+
+namespace = sys.argv[1] if len(sys.argv) > 1 else "default"
+
+os.makedirs("logs", exist_ok=True)
+
+
+def get_pods(namespace="default"):
+    try:
+        result = subprocess.run(
+            ["kubectl", "get", "pods", "-n", namespace, "-o", "name"],
+            capture_output=True, text=True, check=True
+        )
+        pods = [line.replace("pod/", "") for line in result.stdout.strip().splitlines()]
+        return pods
+    except subprocess.CalledProcessError as e:
+        print(f"Error al obtener los pods: {e.stderr}")
+        sys.exit(1)
+
+
+def collect_logs(pods, namespace="default"):
+    for pod in pods:
+        print(f"Recolectando logds del pod: {pod}")
+        with open("logs/all_pods.log", "a", encoding="utf-8") as all_log_file:
+            all_log_file.write(f"=================== Logs del pod: {pod} ===================\n")
+
+            try:
+                log_result = subprocess.run(
+                    ["kubectl", "logs", pod, "-n", namespace],
+                    capture_output=True, text=True, check=True
+                )
+
+                name_pod = pod.replace("timeserver-7c9445b569-", "")
+                pod_log_path = f"logs/{name_pod}.log"
+
+                with open(pod_log_path, "a", encoding="utf-8") as pod_log_file:
+                    pod_log_file.write(log_result.stdout)
+                all_log_file.write(log_result.stdout)
+                all_log_file.write(f"====== Recolección de logs del pod {pod} completada ======\n")
+                all_log_file.write("----------------------------------------------------------\n")
+
+                print(f"Logs del pod {pod} guardados en {pod_log_path}")
+            except subprocess.CalledProcessError as e:
+                print(f"Error al obtener los logs del pod {pod}: {e.stderr}")
+
+
+def get_events(namespace="default"):
+    print("Recolección de eventos del cluster:")
+    with open("logs/all_events.log", "a", encoding="utf-8") as all_log_file:
+        all_log_file.write("=============== Eventos del cluster ===============\n")
+        try:
+            events_result = subprocess.run(
+                ["kubectl", "get", "events", "-n", namespace],
+                capture_output=True, text=True, check=True
+            )
+            all_log_file.write(events_result.stdout)
+            print("Eventos del clúster guardados en log/all_events.log")
+        except subprocess.CalledProcessError as e:
+            print(f"Error al obtener los eventos: {e.stderr}")
+
+
+if __name__ == "__main__":
+    pods = get_pods(namespace)
+    if not pods:
+        print(f"No se encontraron pods en el namespace '{namespace}'.")
+        sys.exit(0)
+
+    collect_logs(pods, namespace)
+    get_events(namespace)
+
+    print("Recolección de logs y eventos completada.")
+    print("Los logs se han guardado en el directorio 'logs'.")
diff --git a/scripts/log_collector.sh b/scripts/log_collector.sh
new file mode 100644
index 0000000..2a4f75c
--- /dev/null
+++ b/scripts/log_collector.sh
@@ -0,0 +1,22 @@
+#!/bin/bash
+
+namespace=${1:-default}
+
+mkdir -p logs
+
+pods=$(kubectl get pods -n "$namespace" -o name | sed 's|pod/||')
+
+for pod in $pods; do
+    echo "=================== Logs del pod: $pod ===================" >> "logs/all_pods.log"
+    kubectl logs "$pod" -n "$namespace" | tee -a "logs/$(echo "$pod" | sed 's|timeserver-7c9445b569-||').log" >> "logs/all_pods.log"
+    echo "====== Recolleción de logs del pod $pod completada =======" >> "logs/all_pods.log"
+    echo "----------------------------------------------------------" >> "logs/all_pods.log"
+    echo "Logs del pod $pod guardados en logs/$(echo "$pod" | sed 's|timeserver-||').log"
+done
+
+echo "Todos los logs han sido guardados en logs/all_pods.log"
+
+echo "===================== Eventos del Cluster =====================" >> "logs/all_pods.log"
+kubectl get events -n "$namespace" >> "logs/all_events.log"
+
+echo "Eventos del cluster guardados en logs/all_events.log"

commit 2b0c7a5e33b75d0d16c4245df118a492f5dc5483
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Wed Jun 25 23:35:37 2025 -0500

    docs(md): Añadir documentación de los scripts log_collector.py y log_collector.sh
---
 scripts/Img/get_default_name_pods.png | Bin 0 -> 11750 bytes
 scripts/Img/get_default_pods.png      | Bin 0 -> 17630 bytes
 scripts/Img/namespaces.png            | Bin 0 -> 42431 bytes
 scripts/Img/namspace_default.png      | Bin 0 -> 18066 bytes
 scripts/Img/namspace_kube.png         | Bin 0 -> 36507 bytes
 scripts/Img/only_podnames.png         | Bin 0 -> 13848 bytes
 scripts/Img/sin_namespace.png         | Bin 0 -> 18059 bytes
 scripts/README-bash.md                |  87 ++++++++++++++++++++++++++++++++++
 scripts/README-python.md              |  55 +++++++++++++++++++++
 9 files changed, 142 insertions(+)

diff --git a/scripts/Img/get_default_name_pods.png b/scripts/Img/get_default_name_pods.png
new file mode 100644
index 0000000..67d1b47
Binary files /dev/null and b/scripts/Img/get_default_name_pods.png differ
diff --git a/scripts/Img/get_default_pods.png b/scripts/Img/get_default_pods.png
new file mode 100644
index 0000000..68848ce
Binary files /dev/null and b/scripts/Img/get_default_pods.png differ
diff --git a/scripts/Img/namespaces.png b/scripts/Img/namespaces.png
new file mode 100644
index 0000000..0a6e00e
Binary files /dev/null and b/scripts/Img/namespaces.png differ
diff --git a/scripts/Img/namspace_default.png b/scripts/Img/namspace_default.png
new file mode 100644
index 0000000..f443a8c
Binary files /dev/null and b/scripts/Img/namspace_default.png differ
diff --git a/scripts/Img/namspace_kube.png b/scripts/Img/namspace_kube.png
new file mode 100644
index 0000000..1bbacc0
Binary files /dev/null and b/scripts/Img/namspace_kube.png differ
diff --git a/scripts/Img/only_podnames.png b/scripts/Img/only_podnames.png
new file mode 100644
index 0000000..e9e61dc
Binary files /dev/null and b/scripts/Img/only_podnames.png differ
diff --git a/scripts/Img/sin_namespace.png b/scripts/Img/sin_namespace.png
new file mode 100644
index 0000000..f263e95
Binary files /dev/null and b/scripts/Img/sin_namespace.png differ
diff --git a/scripts/README-bash.md b/scripts/README-bash.md
new file mode 100644
index 0000000..f262058
--- /dev/null
+++ b/scripts/README-bash.md
@@ -0,0 +1,87 @@
+# Script bash que recolecta todos los logs de los Pods en un namespace específico
+
+## Namespace
+Según la documentación de [vmware](https://www.vmware.com/topics/kubernetes-namespace#:~:text=Los%20espacios%20de%20nombres%20son%20una%20forma%20de%20organizar%20cl%C3%BAsteres%20en%20subgrupos%20virtuales) un namespace **es la forma de organizar clústeres en subgrupos virtuales** así que en este contexto, en lo que debemos enfocarnos es en buscar todos los pods que se alojan en el namespace `default` ya que por defecto se agrupan ahí.
+
+## Explicación de código
+### Namespace específico
+Para definir el namespace a usar, lo que haremos será primero al momento de ejecutar el script, elegir el namespace a usar, con el siguiente comando
+```bash
+namespace=${1:-default}
+```
+Esto basicamente lo que nos dice es, `Al ejecutar el comando bash log_collector.sh, especifica el nombre del namespace a usar, y en caso no especifiques, usaré el namespace default`.
+Y la mejora manera de probar esto, es mediante la ejecución del comando:
+Primero verificamos los namespaces del kubernetes con el comando:
+```bash
+kubectl get pods --all-namespaces
+```
+![Img](Img/namespaces.png)
+
+Ahora para ejecutar, haremos las tres maneras:
+**1.- Ejecutar sin especificar el namespace**
+![Img](Img/sin_namespace.png)
+
+**2.- Ejecutar especificando a default como namespace**
+![Img](Img/namspace_default.png)
+
+**3.- Ejecutar especificando a kube-system como namespace**
+![Img](Img/namspace_kube.png)
+
+### kubectl get pods -n default
+Ahora según lo anterior el comando de get pods, ahora ya tendrá el valor del namespace especificado, y esto nos devolverá solo los pods que pertenecen a ese namespace `kubectl get pods -n "$namespace"`, el cuál nos dará una respuesta parecida a la siguiente
+
+![Img](Img/get_default_pods.png)
+---
+
+Podemos notar que el resultado es obtener todos los pods con las columnas `NAME`, `READY`, `STATUS`, `RESTARTS` y `AGE` pero lo que nos interesa, es solo el nombre, ya que para verificar los logs, necesitamos el nombre del **Pod**
+
+### kubectl get pods -n default -o name
+Así que debido a esa necesidad, se empieza con el filtrado de la respuesta al comando, ejectuando el siguiente comando le pedimos al sistema que nos muestre solo la columna `NAME` de la respuesta general al ejecutar `kubectl get pods`, modificando el comando a `kubectl get pods -n "$namespace" -o name` obteniendo como respuesta lo siguiente:
+
+![Img](Img/get_default_name_pods.png)
+
+### kubectl get pods -n "$namespace" -o name | sed 's|pod/||'
+A pesar de tener un gran avance, para recolectar los logs, decidí por crear un archivo **.log** por cada pod.
+#### Idea de uso:
+El **.log** de cada pod se identificará con la última parte del nombre del pod, la cuál es la única que varía y así sea más rápida su identificación, así que como se vió en la imagen anterior, al solicitar que nos muestre solo la fila `NAME`, esta respuesta, viene acompañada de un `pod/` lo cual no nos sirve para identificar el pod, por lo que usamos `sed 's|pod/||` que se encarga de que al momento de obtener la respuesta, esta respuesta se muestre pero sin el comienzo `pod/` y así nos quedamos con solo en nombre del pod, y ya tenemos listo para usar `kubectl logs`
+
+![Img](Img/only_podnames.png)
+
+Las siguientes líneas solo se encargan de leer los **Pods** que se recogieron y guardar en su archivo correspondiente
+
+### Creación de archivo log (Individual y General)
+```bash
+kubectl logs "$pod" -n "$namespace" | tee -a "logs/$(echo "$pod" | sed 's|timeserver-7c9445b569-||').log" >> "logs/all_pods.log"
+```
+En esta línea del script, lo que hacemos es aplicar el comando `kubectl logs` el cuál se encarga de recolectar los logs del pod que se encuentra en el namespace especificado.
+La segunda parte `tee -a` lo que hace es mostrar en pantalla la respuesta, pero además de eso, guardar en el archivo individual, donde podemos ver que la parte del comando que indica luego del sed, es para eliminar el valor repetido de esos pods y obtener solo el valor distinto del nombre, para así se creen sus archivos con su nombre respectivo, y por último al terminar, toda esa respuesta, se va a guardar en `all_pods.log` y con esto se termina la parte de recolectar logs
+
+# Registar eventos
+Para esta parte del script, lo único que haremos será ejecutar el comando
+```bash
+kubectl get events -n "$namespace"
+```
+Y la respuesta que de, se guardará en el archivo all_pods.log
+
+# Instrucciones
+Primero lo que se tiene que hacer, es que al crear el script, nos dirigimos a la carpeta scripts que es donde está `log_collector.sh` y ejecutamos:
+```bash
+chmod +x log_collector.sh
+```
+El cuál sirve para volver ejecutable al archivo bash
+---
+Ahora para ejecutar el comando, lo único que se debe de hacer es ejecutar el siguiente comando en caso estés dentro de la carpeta scripts:
+```bash
+bash log_collector.sh
+```
+Si se está en la carpeta raiz, la única diferencia al comando será agregar la carpeta scripts:
+```bash
+bash scripts/log_collector.sh
+```
+
+## Ejecutar con namespace específico
+Ahora como la rúbrica indicaba un namespace específico, tal como se indico anteriormente, al momento de ejecutar el script, solo le agregamos el namespace que queremos porque en caso de no agregar, por defecto se realizará al namespace default:
+```bash
+bash log_collector.sh default
+```
+Eso es en caso querramos ese namespace, pero si queremos usar otro namespace, reemplazamos default por el namespace requerido y ejecutamos el script
diff --git a/scripts/README-python.md b/scripts/README-python.md
new file mode 100644
index 0000000..5a93abb
--- /dev/null
+++ b/scripts/README-python.md
@@ -0,0 +1,55 @@
+# Script python que recolecta todos los logs de los Pods en un namespace específico
+
+Teniendo ya definido lo que es un namespace, y previamente implementado el `log_collector.sh`, lo que ahora hacemos es que con el objetivo de poder realizar pruebas unitarias a nuestro script, nos vemos en la necesidad de crear un archivo python que tenga la misma funcionalidad que `log_collector.sh` pero este archivo estará escrito en python, por lo que empezaremos con la explicación del código, cabe recalcar que seré más breve porque algunos conceptos como los comando a aplicar, ya se explicaron en [README-bash.md](README-bash.md)
+
+## Explicación del código
+Empezamos con manera de ejecutar el script python, ya que al igual que en el de bash, podiamos hacer `bash log_collector.sh` o `bash log_collector.sh default` y con ambos comandos, ejecutabamos el script bash con el namespace default por defecto, así que para poner esta forma de ejecutar el script, hacemos uso del siguiente comando:
+```python
+namespace = sys.argv[1] if len(sys.argv) > 1 else "default"
+``` 
+Con esto, tomamos el argumento que se indica al momento de ejecutar el script, y en caso no haya argumento, se tomará por defecto, el namespace `default`
+#### Forma de ejecución
+```bash
+# Sin argumento
+python log_collector.py
+
+# Con argumento
+python log_collector.py default
+```
+
+Y como sabemos que todo se iba a guardar en la carpeta logs, con el siguiente comando hacemos que se cree en caso no exista y nos aseguramos de que se presente algún error
+```bash
+mkdir -p logs
+
+```
+```python
+os.makedirs("logs", exist_ok=True)
+```
+En ambos casos, es la manera que se indica para crear la carpeta `logs`
+
+## Adapando la estructura del código para usarlo con pytest
+A diferencia del script `log_collector.sh` para el archivo `log_collector.py` lo que haremos será crear funciones, las cuales serán las siguientes `get_pods` (Encargada de obtener todos los pods según el namespace y retornar estos pods como una lista para poder guardarlos en una variable al momento de su llamado), `collect_logs` (Encargada de obtener los logs de cada pod y en primera guardarlas en su respectivo archivo `.log` y en segunda, guardar todos los logs, en un archivo general que se llama `all_pods.log`) y por último la función `get_events` (Encargada de obtener todos los eventos ocurridos en un namespace específico y guardarlas en el archivo `all_events.log`) y con estas funciones, se facilita el uso de pytest ya que al crear el archivo [test_collector_log.py](..\tests\test_collector_log.py) donde importamos las funciones y de acuerdo a eso se crearán las pruebas.
+
+
+## Funciones
+
+### Get_pods(namespace="default")
+Esta función tiene la opción de recibir un argumento llamado `namespace` pero en caso al momento de llamarla, no se le asigne argumento alguno, por defecto tomará a `namespace` como `default`
+En un primer momento, lo que se hará será verificar que hayan pods existentes en el namespace dado al momento de ejecutar el comando `kubectl get pods -n namespace -o name`, y en caso no hayan pods en ese namespace, nos botará un error el cual nos dará como respuesta el siguiente mensaje `Error al obtener los pods`
+Tomando el caso donde no hay error al ejecutar el comando, lo que haremos será eliminar la palabra `pod/` que aparece en el resultado del comando, para que solo nos aparezca el nombre en si del pod (la palabra correcta no sería eliminar tecnicamente, lo que hacemos es que con el comando `replace("pod/", "")` lo que hacemos es reemplazar el string `pods/` con un string vacío, así que formalmente es reemplazar el string por uno vacío pero creo que también sería válido decir eliminar ese string), luego de eso, lo que se hace es guardar el nombre de **todos** los pods obtenidos luego del ajuste de su nombre en una variable `pods`, para luego esa variable, retornarla como resultado de invocar la función **get_pods** y hacemos esto para luego invocar la función **collect_logs** el cuál necesita como argumento, un namespace (opcional) y el nombre de los pods sobre los cuales buscar el log
+
+### Collect_logs(pods, namespace="default")
+Esta función es basicamente tomar cada elemento de la lista **pods** (como se explicó antes, la lista guarda el nombre de los pods del namespace elegido), guardar el elemento en una variable **pod** y según esta variable ejecutar el comando `kubectl logs pod -n namespace` para de esa manera, obtener el log de cada pod, y este resultado, primero se guardará en el archivo `all_pods.log` y luego, se guardará en un archivo `pod.log` donde pod será el nombre del elemento que se está tomando por el momento, eso se hace para que hasta este punto, tener **n+1** archivos `.log`, donde este **1** será el archivo `all_pods.log` que guardará los resultados de todos los logs que se tienen de cada pod, y el **n** son los **n** pods que se tienen o matematicamente **n=len(pods)** y como ya se sabe, **pods** es una lista con todos los nombres de los pods existentes en el namespace elegido.
+
+### Get_events(namespace="default")
+Por último, esta función, se encarga de obtener todos los eventos ocurridos en el namespace elegido, ejecutando el comando `kubectl get events -n namespace` y guardando la respuesta en el archivo `all_events.log`
+
+# Instrucción de ejecución
+La forma de ejecutar este archivo, es similar al del archivo bash, podemos ejecutarlo señalando el namespace, o no y se tomará por defecto a default, así que suponiendo estamos dentro de la carpeta scripts que es donde se encuentra el script, ejecutamos el comando
+```bash
+python log_collector.py
+```
+Y en caso estemos en la carpeta raíz, modificamos el comando
+```bash
+python scripts/log_collector.py
+```

commit c2f55fb892f86e6f116a1742646c00fc6e176c30
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Wed Jun 25 23:37:08 2025 -0500

    test(py): Agregar pruebas con marcas xfail y skip para el archivo log_collector.py
---
 pytest.ini                  |   2 ++
 tests/Img/Resultados.png    | Bin 0 -> 32064 bytes
 tests/README.md             |  18 +++++++++++++++++
 tests/test_collector_log.py |  48 ++++++++++++++++++++++++++++++++++++++++++++
 4 files changed, 68 insertions(+)

diff --git a/pytest.ini b/pytest.ini
new file mode 100644
index 0000000..03f586d
--- /dev/null
+++ b/pytest.ini
@@ -0,0 +1,2 @@
+[pytest]
+pythonpath = .
\ No newline at end of file
diff --git a/tests/Img/Resultados.png b/tests/Img/Resultados.png
new file mode 100644
index 0000000..d61ad1e
Binary files /dev/null and b/tests/Img/Resultados.png differ
diff --git a/tests/README.md b/tests/README.md
new file mode 100644
index 0000000..9fe1e82
--- /dev/null
+++ b/tests/README.md
@@ -0,0 +1,18 @@
+# Aplicación de marcas (xfail, skip) para pruebas de recolección de logs
+
+Para realizar estas pruebas, lo primero que se hará será importar las funciones que se crearon en [log_collector.py](../scripts/log_collector.py) y sobre la cuál haremos uso de las marcas **xfail** (para pruebas que de antemano se saben que van a fallar, es decir, se espera que halla error y en este contexto podría ser, porque no existe el namespace elegido), **skip** (para omitir esa prueba por varios motivos y en este contexto, podría ser poque aún no están disponibles los pods para un namespace determinado)
+
+## Prueba sin marca
+Para comenzar con el testeo, primero haremos una prueba que sabemos que pasará, la cuál trata de usar el namespace `default`, y de acuerdo a esto, va a usar la función `get_pods(namespace)` para obtener los pods y así guardarlo en la variable **pods**, y como no es necesario usar la función `collect_logs` lo que hacemos es verificar que esta variable **pods** no está vacía `len(pods) > 0`, que sea de tipo **list** `isinstance(pods, list)`, que tenga un valor asignado, no sea **None** `pods is not None` y de acuerdo a esto, se verificará si hay erro o no, porque si hay un elemento en **pods** este elemento significa que exite en ese namespace, y no habrá problema al verificar su log.
+
+## Prueba con marca skip
+En esta prueba, no importa que contenga la prueba, ya que si o si se va a excluir sin importar si falla o nop, por ello es que notamos que su lógica dentro de la función, es la misma que la de `test_get_existent_logs`, pero al momento de ejecutar pytest, omitirá esta prueba
+
+## Prueba con marca xfail - Falla esperada 
+Para esta prueba, lo que buscamos es obtener un resultado fallido, forzar un fallo, es decir, hacer que al momento de ejecutar las funciones, este nos de error, y para esto se creó previamente **namespace2**, una variable que tiene como valor `inexsitent_pods` con el objetivo de tener un nombre de namespace que no exista, para así al momento de realizar `get_pods(namespace2)` nos de un error porque no hay pods agrupados en ese namespace, por lo que al realizar `pods = get_pods(namespace2)` lo que obtenemos es que **pods** no tenga un valor asignado y al momento de buscar su log con `collect_logs(pods[0], namespace=namespace2)` este nos dará error ya que **pods** es None o una lista vacía
+
+## Prueba de marca xfail - Aprobación no esperada
+La diferencia que tiene est prueba con la anterior, es que de por si, con la marca xfail se avisa al sistema que la función va a fallar, pero **¿Qué pasa si la prueba no falla y se ha avisado al sistema que si?** pues la verdad, no pasa nada, lo único es que al momento de ejecutar las pruebas, la notación de xfail será distinta a cuando se espera que falle y falla, ya que cuando la prueba falla y se usa xfail, se denota con una **x** (xfail) pero cuando la prueba no falla y se usa xfail, se denota con una **X** (xpassed)
+
+# Ejecución de pytest
+![Img](Img/Resultados.png)
diff --git a/tests/test_collector_log.py b/tests/test_collector_log.py
new file mode 100644
index 0000000..a4c872f
--- /dev/null
+++ b/tests/test_collector_log.py
@@ -0,0 +1,48 @@
+import pytest
+import subprocess
+from scripts.log_collector import get_pods, collect_logs, get_events
+
+namespace = "default"
+
+namespace2 = "inexsitent_pods"
+
+
+def test_get_existent_logs():
+    pods = get_pods(namespace)
+    assert len(pods) > 0
+    assert isinstance(pods, list)
+    assert pods is not None
+
+
+@pytest.mark.skip(reason="No hay pods disponibles en el namespace indicado")
+def test_get_inexistent_pods():
+    pods = get_pods(namespace)
+    assert pods is not None
+    assert isinstance(pods, list)
+    assert len(pods) > 0, "No se encontraron pods en el namespace especificado"
+
+
+@pytest.mark.xfail(reason="Algún pod no está disponible")
+def test_collect_logs_xfail_and_fail():
+    pods = get_pods(namespace2)
+    if not pods:
+        pytest.xfail("No hay pods disponibles en el namespace indicado")
+
+    collect_logs(pods[0], namespace=namespace2)
+    subprocess.run(
+        ["rm", "-r", "logs"],
+        capture_output=True, text=True, check=True
+    )
+
+
+@pytest.mark.xfail(reason="Algún pod no está disponible")
+def test_collect_logs_xfail_not_fail():
+    pods = get_pods(namespace)
+    if not pods:
+        pytest.xfail("No hay pods disponibles en el namespace indicado")
+
+    collect_logs(pods[0], namespace=namespace2)
+    subprocess.run(
+        ["rm", "-r", "logs"],
+        capture_output=True, text=True, check=True
+    )

commit 6cfcc8aacb215f3e954dc84bc0ebd91d16508782
Merge: 4d244dc c2f55fb
Author: Alex Vega <91773368+axvg@users.noreply.github.com>
Date:   Wed Jun 25 23:48:21 2025 -0500

    Merge pull request #17 from grupo10-CC3S2/feature/scripts/collect_logs_and_events
    
    Implementar recolección de logs y eventos para un namespace específico

commit 6118c719e9f64ed726ae61b5b4146598749667ee
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Thu Jun 26 01:10:12 2025 -0500

    docs(sprint1): Agregar video de finalización de sprint1
---
 videos/README.md | 11 +++++++++++
 1 file changed, 11 insertions(+)

diff --git a/videos/README.md b/videos/README.md
new file mode 100644
index 0000000..7816260
--- /dev/null
+++ b/videos/README.md
@@ -0,0 +1,11 @@
+# Links de videos de cada sprint
+
+## Integrantes:
+
+### Alex Vega
+### Christian Luna
+### Jesus Osorio
+
+## Sprint-1
+
+[Video Sprint 1](https://drive.google.com/file/d/1tIrF-FU1v7B8dVrN-dbGRqnPmfwTTgwl/view?usp=drive_link)
\ No newline at end of file

commit d74dd540478161128f35aa96bb54d80dd705d031
Merge: 6cfcc8a 6118c71
Author: Christian Luna Jaramillo <65150753+Chriss5-2@users.noreply.github.com>
Date:   Thu Jun 26 02:54:39 2025 -0500

    Merge pull request #18 from grupo10-CC3S2/videos/sprint1
    
    Video de explicación del sprint1

commit e71cb5328caf1c1658b52b2f4206aa845b3042d7
Merge: f6a5bf9 d74dd54
Author: Alex Vega <91773368+axvg@users.noreply.github.com>
Date:   Thu Jun 26 18:07:26 2025 -0500

    Merge pull request #19 from grupo10-CC3S2/develop
    
    Sprint_1: Recolección de logs y eventos

commit f924f9ba69cee1280cd0dc94a97b649f384c2297
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 00:17:52 2025 -0500

    feat(make): agrega comando para obtener dos versiones de images
---
 Makefile  | 17 +++++++++++++++++
 README.md |  3 ++-
 2 files changed, 19 insertions(+), 1 deletion(-)

diff --git a/Makefile b/Makefile
new file mode 100644
index 0000000..79cb82d
--- /dev/null
+++ b/Makefile
@@ -0,0 +1,17 @@
+REPO = "https://github.com/grupo10-CC3S2/test-repo-pc4"
+
+setup-v1:
+	docker build -t timeserver:v1 app
+	kubectl cluster-info
+	kubectl apply -f k8s/
+	kubectl get pods
+
+setup-v2:
+	docker build -t timeserver:v2 app
+	kubectl apply -f k8s/
+	kubectl get pods
+
+teardown:
+	kubectl delete -f k8s/
+	docker image rm timeserver:v1
+	docker image rm timeserver:v2
\ No newline at end of file
diff --git a/README.md b/README.md
index 8dfb58f..a2d2382 100644
--- a/README.md
+++ b/README.md
@@ -11,7 +11,8 @@
 
 1. Construir la imagen Docker local:
    ```sh
-   docker build -t timeserver:latest app
+   docker build -t timeserver:v1 app
+   docker build -t timeserver:v2 app
    ```
 2. Verificar que Kubernetes esta activado:
    ```sh

commit d145309c6dd389df8c12958e5e2b0d8a61f55aee
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 00:30:23 2025 -0500

    feat(py): agrega logger service para app, en 3 niveles
---
 app/logger_service.py | 48 ++++++++++++++++++++++++++++++++++++++++++++++++
 app/server.py         |  6 +++++-
 2 files changed, 53 insertions(+), 1 deletion(-)

diff --git a/app/logger_service.py b/app/logger_service.py
new file mode 100644
index 0000000..356a476
--- /dev/null
+++ b/app/logger_service.py
@@ -0,0 +1,48 @@
+import logging
+import time
+import threading
+from datetime import datetime, timezone
+
+logging.basicConfig(
+    level=logging.INFO,
+    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+)
+
+logger = logging.getLogger(__name__)
+
+stop_logging = False
+
+
+def periodic_warning_logs():
+    warning_count = 1
+    logger.info("logs nivel warning")
+
+    while not stop_logging:
+        time.sleep(10)
+        if not stop_logging:
+            timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
+            logger.warning(f"warning #{warning_count} at {timestamp}")
+            warning_count += 1
+
+
+def periodic_error_logs():
+    error_count = 1
+    logger.info("logs nivel error")
+
+    while not stop_logging:
+        time.sleep(20)
+        if not stop_logging:
+            timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
+            logger.error(f"error #{error_count} at {timestamp}")
+            error_count += 1
+
+
+def start_background_logging():
+    logger.info("log nivel info start")
+    warning_thread = threading.Thread(target=periodic_warning_logs, daemon=True)
+    warning_thread.start()
+
+    error_thread = threading.Thread(target=periodic_error_logs, daemon=True)
+    error_thread.start()
+
+    logger.info("log nivel info end")
diff --git a/app/server.py b/app/server.py
index c202fec..129c4f7 100644
--- a/app/server.py
+++ b/app/server.py
@@ -1,6 +1,8 @@
 from flask import Flask, Response
 from datetime import datetime, timezone
 from zoneinfo import ZoneInfo
+from logger_service import start_background_logging, logger
+
 
 app = Flask(__name__)
 
@@ -18,4 +20,6 @@ def get_current_time():
 
 
 if __name__ == "__main__":
-    app.run(host='0.0.0.0', port=80)
\ No newline at end of file
+    start_background_logging()
+    logger.info("Flask server starting on 0.0.0.0:80")
+    app.run(host='0.0.0.0', port=80)

commit dfa1982e7e4f57df03f218a50c0da04e00faaf2d
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 00:33:32 2025 -0500

    feat(dev): agrega devcontainer para uso de fluxcd
---
 .devcontainer/devcontainer.json | 32 ++++++++++++++++++++++++++++++++
 1 file changed, 32 insertions(+)

diff --git a/.devcontainer/devcontainer.json b/.devcontainer/devcontainer.json
new file mode 100644
index 0000000..e1c2895
--- /dev/null
+++ b/.devcontainer/devcontainer.json
@@ -0,0 +1,32 @@
+{
+	"name": "k8s devcontainer",
+
+	"image": "mcr.microsoft.com/devcontainers/base:bullseye",
+
+	"features": {
+		"ghcr.io/devcontainers/features/kubectl-helm-minikube:1": {
+			"version": "latest",
+			"helm": "none",
+			"minikube": "none"
+		},
+		"ghcr.io/devcontainers/features/git:1": {}
+	},
+
+	"postCreateCommand": "curl -s https://fluxcd.io/install.sh | bash",
+
+	"mounts": [
+		"source=/var/run/docker.sock,target=/var/run/docker.sock,type=bind",
+		"source=${localEnv:HOME}/.kube,target=/home/vscode/.kube,type=bind,consistency=cached"
+	],
+
+	"customizations": {
+		"vscode": {
+			"extensions": [
+				"ms-kubernetes-tools.vscode-kubernetes",
+				"ms-azuretools.vscode-docker",
+				"weaveworks.vscode-flux",
+				"redhat.vscode-yaml"
+			]
+		}
+	}
+}
\ No newline at end of file

commit 20805e2bac970f5d8a101f164452b91339572315
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 02:37:54 2025 -0500

    feat(yaml): actualiza version, agrega namespace para fluxcd
---
 k8s/deploy.yaml  | 3 ++-
 k8s/service.yaml | 1 +
 2 files changed, 3 insertions(+), 1 deletion(-)

diff --git a/k8s/deploy.yaml b/k8s/deploy.yaml
index 31585a8..67ede29 100644
--- a/k8s/deploy.yaml
+++ b/k8s/deploy.yaml
@@ -2,6 +2,7 @@ apiVersion: apps/v1
 kind: Deployment
 metadata:
   name: timeserver
+  namespace: default
 spec:
   replicas: 3
   selector:
@@ -14,5 +15,5 @@ spec:
     spec:
       containers:
       - name: timeserver-container
-        image: timeserver:latest
+        image: timeserver:v1
         imagePullPolicy: Never
\ No newline at end of file
diff --git a/k8s/service.yaml b/k8s/service.yaml
index 642f9ff..d358ae5 100644
--- a/k8s/service.yaml
+++ b/k8s/service.yaml
@@ -2,6 +2,7 @@ apiVersion: v1
 kind: Service
 metadata:
   name: timeserver
+  namespace: default
 spec:
   selector:
     pod: timeserver-pod

commit b44c68a1252c673147b3de71a8294014e2fe7952
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 02:42:06 2025 -0500

    feat(make): agrega opciones para gitops para el uso facil de fluxcd
---
 Makefile | 25 ++++++++++++++++++++++++-
 1 file changed, 24 insertions(+), 1 deletion(-)

diff --git a/Makefile b/Makefile
index 79cb82d..3100890 100644
--- a/Makefile
+++ b/Makefile
@@ -14,4 +14,27 @@ setup-v2:
 teardown:
 	kubectl delete -f k8s/
 	docker image rm timeserver:v1
-	docker image rm timeserver:v2
\ No newline at end of file
+	docker image rm timeserver:v2
+
+# GitOps
+
+flux-init:
+	flux check --pre
+	flux install
+
+flux-creater:
+	flux create source git repo-github --url=$(REPO) --branch=main --interval=30s --export > ./flux-gitrepository.yaml
+	kubectl apply -f ./flux-gitrepository.yaml
+
+flux-createk:
+	flux create kustomization kustomization-github --source=GitRepository/repo-github --path="./k8s" --prune=true --interval=30s --export > ./flux-kustomization.yaml
+	kubectl apply -f ./flux-kustomization.yaml
+
+flux-getk:
+	flux get kustomizations
+
+flux-watchk:
+	flux get kustomizations --watch
+
+pod-images:
+	kubectl get pods -n default -l pod=timeserver-pod -o jsonpath='{.items[*].spec.containers[*].image}'
\ No newline at end of file

commit 957948ae36f54b219b630c94b220e258e19d9682
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 02:46:16 2025 -0500

    feat(yaml): agrega archivos gitops de fluxcd
---
 flux-gitrepository.yaml | 11 +++++++++++
 flux-kustomization.yaml | 13 +++++++++++++
 2 files changed, 24 insertions(+)

diff --git a/flux-gitrepository.yaml b/flux-gitrepository.yaml
new file mode 100644
index 0000000..ce1e66b
--- /dev/null
+++ b/flux-gitrepository.yaml
@@ -0,0 +1,11 @@
+---
+apiVersion: source.toolkit.fluxcd.io/v1
+kind: GitRepository
+metadata:
+  name: repo-github
+  namespace: flux-system
+spec:
+  interval: 30s
+  ref:
+    branch: main
+  url: https://github.com/grupo10-CC3S2/test-repo-pc4
diff --git a/flux-kustomization.yaml b/flux-kustomization.yaml
new file mode 100644
index 0000000..bb7d6a0
--- /dev/null
+++ b/flux-kustomization.yaml
@@ -0,0 +1,13 @@
+---
+apiVersion: kustomize.toolkit.fluxcd.io/v1
+kind: Kustomization
+metadata:
+  name: kustomization-github
+  namespace: flux-system
+spec:
+  interval: 30s
+  path: ./k8s
+  prune: true
+  sourceRef:
+    kind: GitRepository
+    name: repo-github

commit 41ac887bded3a9ddf78b59e65ce7bfb02e60d068
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 17:00:53 2025 -0500

    fix(py): Actualiza log_collector.py y agrupa en carpetas
---
 .../Img/get_default_name_pods.png                  | Bin
 .../{ => log_collector}/Img/get_default_pods.png   | Bin
 scripts/{ => log_collector}/Img/namespaces.png     | Bin
 .../{ => log_collector}/Img/namspace_default.png   | Bin
 scripts/{ => log_collector}/Img/namspace_kube.png  | Bin
 scripts/{ => log_collector}/Img/only_podnames.png  | Bin
 scripts/{ => log_collector}/Img/sin_namespace.png  | Bin
 scripts/{ => log_collector}/README-bash.md         |   0
 scripts/{ => log_collector}/README-python.md       |   0
 scripts/{ => log_collector}/log_collector.py       |  26 +++++++++++++++++----
 scripts/{ => log_collector}/log_collector.sh       |   0
 11 files changed, 21 insertions(+), 5 deletions(-)

diff --git a/scripts/Img/get_default_name_pods.png b/scripts/log_collector/Img/get_default_name_pods.png
similarity index 100%
rename from scripts/Img/get_default_name_pods.png
rename to scripts/log_collector/Img/get_default_name_pods.png
diff --git a/scripts/Img/get_default_pods.png b/scripts/log_collector/Img/get_default_pods.png
similarity index 100%
rename from scripts/Img/get_default_pods.png
rename to scripts/log_collector/Img/get_default_pods.png
diff --git a/scripts/Img/namespaces.png b/scripts/log_collector/Img/namespaces.png
similarity index 100%
rename from scripts/Img/namespaces.png
rename to scripts/log_collector/Img/namespaces.png
diff --git a/scripts/Img/namspace_default.png b/scripts/log_collector/Img/namspace_default.png
similarity index 100%
rename from scripts/Img/namspace_default.png
rename to scripts/log_collector/Img/namspace_default.png
diff --git a/scripts/Img/namspace_kube.png b/scripts/log_collector/Img/namspace_kube.png
similarity index 100%
rename from scripts/Img/namspace_kube.png
rename to scripts/log_collector/Img/namspace_kube.png
diff --git a/scripts/Img/only_podnames.png b/scripts/log_collector/Img/only_podnames.png
similarity index 100%
rename from scripts/Img/only_podnames.png
rename to scripts/log_collector/Img/only_podnames.png
diff --git a/scripts/Img/sin_namespace.png b/scripts/log_collector/Img/sin_namespace.png
similarity index 100%
rename from scripts/Img/sin_namespace.png
rename to scripts/log_collector/Img/sin_namespace.png
diff --git a/scripts/README-bash.md b/scripts/log_collector/README-bash.md
similarity index 100%
rename from scripts/README-bash.md
rename to scripts/log_collector/README-bash.md
diff --git a/scripts/README-python.md b/scripts/log_collector/README-python.md
similarity index 100%
rename from scripts/README-python.md
rename to scripts/log_collector/README-python.md
diff --git a/scripts/log_collector.py b/scripts/log_collector/log_collector.py
similarity index 76%
rename from scripts/log_collector.py
rename to scripts/log_collector/log_collector.py
index de5609e..eea11db 100644
--- a/scripts/log_collector.py
+++ b/scripts/log_collector/log_collector.py
@@ -1,10 +1,26 @@
 import os
 import subprocess
 import sys
+from pathlib import Path
+
+
+def find_root_dir(target_folder_name):
+    current = Path(__file__).resolve()
+    while current.name != target_folder_name:
+        if current.parent == current:
+            raise FileNotFoundError(f"No se encontró el directorio '{target_folder_name}' hacia arriba desde {__file__}")
+        current = current.parent
+    return current
+
 
 namespace = sys.argv[1] if len(sys.argv) > 1 else "default"
 
-os.makedirs("logs", exist_ok=True)
+
+root_dir = find_root_dir("test-repo-pc4")
+
+
+logs_dir = root_dir / "logs"
+logs_dir.mkdir(exist_ok=True)
 
 
 def get_pods(namespace="default"):
@@ -23,7 +39,7 @@ def get_pods(namespace="default"):
 def collect_logs(pods, namespace="default"):
     for pod in pods:
         print(f"Recolectando logds del pod: {pod}")
-        with open("logs/all_pods.log", "a", encoding="utf-8") as all_log_file:
+        with open(logs_dir / "all_pods.log", "a", encoding="utf-8") as all_log_file:
             all_log_file.write(f"=================== Logs del pod: {pod} ===================\n")
 
             try:
@@ -33,7 +49,7 @@ def collect_logs(pods, namespace="default"):
                 )
 
                 name_pod = pod.replace("timeserver-7c9445b569-", "")
-                pod_log_path = f"logs/{name_pod}.log"
+                pod_log_path = logs_dir / f"{name_pod}.log"
 
                 with open(pod_log_path, "a", encoding="utf-8") as pod_log_file:
                     pod_log_file.write(log_result.stdout)
@@ -48,7 +64,7 @@ def collect_logs(pods, namespace="default"):
 
 def get_events(namespace="default"):
     print("Recolección de eventos del cluster:")
-    with open("logs/all_events.log", "a", encoding="utf-8") as all_log_file:
+    with open(logs_dir / "all_events.log", "a", encoding="utf-8") as all_log_file:
         all_log_file.write("=============== Eventos del cluster ===============\n")
         try:
             events_result = subprocess.run(
@@ -56,7 +72,7 @@ def get_events(namespace="default"):
                 capture_output=True, text=True, check=True
             )
             all_log_file.write(events_result.stdout)
-            print("Eventos del clúster guardados en log/all_events.log")
+            print(f"Eventos del clúster guardados en {logs_dir / 'all_events.log'}")
         except subprocess.CalledProcessError as e:
             print(f"Error al obtener los eventos: {e.stderr}")
 
diff --git a/scripts/log_collector.sh b/scripts/log_collector/log_collector.sh
similarity index 100%
rename from scripts/log_collector.sh
rename to scripts/log_collector/log_collector.sh

commit acc663195360a1d0357737464f76956aad5c6790
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 17:03:13 2025 -0500

    fix(py): Actualiza log_collector.py
---
 scripts/log_collector/log_collector.py | 28 +++++++++++++++++++++-------
 1 file changed, 21 insertions(+), 7 deletions(-)

diff --git a/scripts/log_collector/log_collector.py b/scripts/log_collector/log_collector.py
index eea11db..2107216 100644
--- a/scripts/log_collector/log_collector.py
+++ b/scripts/log_collector/log_collector.py
@@ -8,7 +8,9 @@ def find_root_dir(target_folder_name):
     current = Path(__file__).resolve()
     while current.name != target_folder_name:
         if current.parent == current:
-            raise FileNotFoundError(f"No se encontró el directorio '{target_folder_name}' hacia arriba desde {__file__}")
+            raise FileNotFoundError(
+                f"No se encontró el directorio '{target_folder_name}' hacia arriba desde {__file__}"
+            )
         current = current.parent
     return current
 
@@ -27,7 +29,9 @@ def get_pods(namespace="default"):
     try:
         result = subprocess.run(
             ["kubectl", "get", "pods", "-n", namespace, "-o", "name"],
-            capture_output=True, text=True, check=True
+            capture_output=True,
+            text=True,
+            check=True,
         )
         pods = [line.replace("pod/", "") for line in result.stdout.strip().splitlines()]
         return pods
@@ -40,12 +44,16 @@ def collect_logs(pods, namespace="default"):
     for pod in pods:
         print(f"Recolectando logds del pod: {pod}")
         with open(logs_dir / "all_pods.log", "a", encoding="utf-8") as all_log_file:
-            all_log_file.write(f"=================== Logs del pod: {pod} ===================\n")
+            all_log_file.write(
+                f"=================== Logs del pod: {pod} ===================\n"
+            )
 
             try:
                 log_result = subprocess.run(
                     ["kubectl", "logs", pod, "-n", namespace],
-                    capture_output=True, text=True, check=True
+                    capture_output=True,
+                    text=True,
+                    check=True,
                 )
 
                 name_pod = pod.replace("timeserver-7c9445b569-", "")
@@ -54,8 +62,12 @@ def collect_logs(pods, namespace="default"):
                 with open(pod_log_path, "a", encoding="utf-8") as pod_log_file:
                     pod_log_file.write(log_result.stdout)
                 all_log_file.write(log_result.stdout)
-                all_log_file.write(f"====== Recolección de logs del pod {pod} completada ======\n")
-                all_log_file.write("----------------------------------------------------------\n")
+                all_log_file.write(
+                    f"====== Recolección de logs del pod {pod} completada ======\n"
+                )
+                all_log_file.write(
+                    "----------------------------------------------------------\n"
+                )
 
                 print(f"Logs del pod {pod} guardados en {pod_log_path}")
             except subprocess.CalledProcessError as e:
@@ -69,7 +81,9 @@ def get_events(namespace="default"):
         try:
             events_result = subprocess.run(
                 ["kubectl", "get", "events", "-n", namespace],
-                capture_output=True, text=True, check=True
+                capture_output=True,
+                text=True,
+                check=True,
             )
             all_log_file.write(events_result.stdout)
             print(f"Eventos del clúster guardados en {logs_dir / 'all_events.log'}")

commit f5a11ed5c2dee38258e26b3e0cb062c351e978ac
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 17:10:01 2025 -0500

    docs(txt): Actualiza las dependencias necesarias para el proyecto
---
 requirements.txt | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/requirements.txt b/requirements.txt
index c4c6180..b025dd9 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -5,4 +5,7 @@ pytest
 pytest-cov
 pytest-mock
 pytest-html
-kubernetes
\ No newline at end of file
+kubernetes
+pandas
+tabulate
+plotly.express
\ No newline at end of file

commit 0aa40265c9758426473f2bdca200ce18e0864347
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 17:11:10 2025 -0500

    feat(py): Añade metric_collector.py con documentación
---
 scripts/metric_collector/README-collector.md   |  42 ++++++++
 scripts/metric_collector/imgs/1.png            | Bin 0 -> 10278 bytes
 scripts/metric_collector/imgs/2.png            | Bin 0 -> 14344 bytes
 scripts/metric_collector/imgs/3.png            | Bin 0 -> 10727 bytes
 scripts/metric_collector/imgs/conf-metrics.png | Bin 0 -> 10878 bytes
 scripts/metric_collector/metric_collector.py   | 128 +++++++++++++++++++++++++
 6 files changed, 170 insertions(+)

diff --git a/scripts/metric_collector/README-collector.md b/scripts/metric_collector/README-collector.md
new file mode 100644
index 0000000..ab016a3
--- /dev/null
+++ b/scripts/metric_collector/README-collector.md
@@ -0,0 +1,42 @@
+# Recolector de métricas de los Pods y Nodos
+
+Para obtener estás métricas(uso de CPU, memoria) usaremos `kubectl top`.  Ahora para que esto nos funcione necesitamos tener `metrics-server` instalado en nuestro clúster.
+
+1. Verificamos nuestro clúster actual, con el comando `kubectl config current-context`, en nuestro caso es docker-desktop. Luego verificamos si `metrics-server` está instalado, lo cual sabemos que aún no lo tenenmos.
+2. Ya que nuestro clúster es docker-desktop, procedemos a instalar `metrics-server` de la siguiente manera. 
+    ```sh
+    # Descargar e instalar la versión más reciente
+    kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
+
+    # Editamos el deployment
+    kubectl edit deployment metrics-server -n kube-system
+    ```
+    Al ejecutar el último comando se nos abrirá un editor de texto. En el cual tenemos que buscar la sección
+    ```yaml
+    spec:
+      containers:
+      - args:
+        - --cert-dir=/tmp
+        - --secure-port=4443
+        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
+        - --kubelet-use-node-status-port
+        - --metric-resolution=15s
+    ```
+
+    Al encontrarlo añadimos `- --kubelet-insecure-tls`.
+
+    ![](imgs/conf-metrics.png) 
+
+3. Guardamos y salimos. Comprobamos que hayamos hecho todos los pasos correctamente y por ende esté instalado correctamente.
+
+    ![](imgs/1.png)
+
+    - kubectl top pods
+
+        ![](imgs/2.png)
+
+    - kubectl top node
+
+        ![](imgs/3.png)
+
+
diff --git a/scripts/metric_collector/imgs/1.png b/scripts/metric_collector/imgs/1.png
new file mode 100644
index 0000000..9bf1041
Binary files /dev/null and b/scripts/metric_collector/imgs/1.png differ
diff --git a/scripts/metric_collector/imgs/2.png b/scripts/metric_collector/imgs/2.png
new file mode 100644
index 0000000..f70d5ab
Binary files /dev/null and b/scripts/metric_collector/imgs/2.png differ
diff --git a/scripts/metric_collector/imgs/3.png b/scripts/metric_collector/imgs/3.png
new file mode 100644
index 0000000..18982f7
Binary files /dev/null and b/scripts/metric_collector/imgs/3.png differ
diff --git a/scripts/metric_collector/imgs/conf-metrics.png b/scripts/metric_collector/imgs/conf-metrics.png
new file mode 100644
index 0000000..5d9ca5c
Binary files /dev/null and b/scripts/metric_collector/imgs/conf-metrics.png differ
diff --git a/scripts/metric_collector/metric_collector.py b/scripts/metric_collector/metric_collector.py
new file mode 100644
index 0000000..ea498e0
--- /dev/null
+++ b/scripts/metric_collector/metric_collector.py
@@ -0,0 +1,128 @@
+import os
+from pathlib import Path
+import sys
+import subprocess
+import pandas as pd
+from tabulate import tabulate
+import plotly.express as px
+import json
+
+# Comandos para obtener métricas de pods y nodes
+# 1.- kubectl top pods -n <namespace>
+# 2.- kubectl top pods
+# 3.- kubectl top nodes
+
+
+def find_root_dir(target_folder_name):
+    '''
+    Busca el directorio raíz del proyecto para el nombre de carpeta especificado.
+    '''
+    current = Path(__file__).resolve()
+    while current.name != target_folder_name:
+        if current.parent == current:
+            raise FileNotFoundError(f"No se encontró el directorio '{target_folder_name}' hacia arriba desde {__file__}")
+        current = current.parent
+    return current
+
+
+root_dir = find_root_dir("test-repo-pc4")
+
+metrics_dir = root_dir / "metrics"
+metrics_dir.mkdir(exist_ok=True)
+
+
+def get_namespaces():
+    namespaces = subprocess.run(["kubectl", "get", "namespaces", "-o", "name"], capture_output=True, text=True, check=True)
+    all_namespaces = [line.replace("namespace/", "") for line in namespaces.stdout.strip().splitlines()]
+    return all_namespaces
+
+
+def get_nodes():
+    nodes = subprocess.run(["kubectl", "get", "nodes", "-o", "name"], capture_output=True, text=True, check=True)
+    all_nodes = [line.replace("node/", "") for line in nodes.stdout.strip().splitlines()]
+    return all_nodes
+
+
+def collect_metrics__pods(namespaces):
+    pods_dir = metrics_dir / "pods"
+    pods_dir.mkdir(exist_ok=True)
+    print("Recolectando métricas de todos los pods...")
+    for names in namespaces:
+        with open(pods_dir / f"{names}_metrics.csv", "a", encoding="utf-8") as pod_metrics_file:
+            try:
+                metrics_result = subprocess.run(
+                    ["kubectl", "top", "pods", "-n", names],
+                    capture_output=True, text=True, check=True
+                )
+                pod_metrics_file.write(metrics_result.stdout)
+                lines = metrics_result.stdout.strip().split("\n")
+                if len(lines) > 1:
+                    headers = lines[0].split()
+                    metrics = []
+
+                    for line in lines[1:]:
+                        values = line.split()
+                        metrics.append(dict(zip(headers, values)))
+
+                    json_path = pods_dir / f"{names}_metrics.json"
+                    with open(json_path, "w", encoding="utf-8") as jf:
+                        json.dump(metrics, jf, indent=2)
+            except subprocess.CalledProcessError as e:
+                print(f"Error al obtener métricas de los pods en el namespace {names}: {e.stderr}")
+    path = metrics_dir / "pods"
+    archivos = os.listdir(path)
+    print(f"Recolección de métricas de pods completada y guardados en: {archivos}")
+    print("=========================================================")
+
+
+def collect_metrics__nodes(nodes):
+    nodes_dir = metrics_dir / "nodes"
+    nodes_dir.mkdir(exist_ok=True)
+    print("Recolectando métricas de todos los nodos...")
+    for node in nodes:
+        with open(nodes_dir / f"{node}_metrics.csv", "a", encoding="utf-8") as node_metrics_file:
+            try:
+                metrics_result = subprocess.run(
+                    ["kubectl", "top", "nodes"],
+                    capture_output=True, text=True, check=True
+                )
+                node_metrics_file.write(metrics_result.stdout)
+                lines = metrics_result.stdout.strip().split("\n")
+                if len(lines) > 1:
+                    headers = lines[0].split()
+                    metrics = []
+
+                    for line in lines[1:]:
+                        values = line.split()
+                        metrics.append(dict(zip(headers, values)))
+
+                    json_path = nodes_dir / f"{node}_metrics.json"
+                    with open(json_path, "w", encoding="utf-8") as jf:
+                        json.dump(metrics, jf, indent=2)
+            except subprocess.CalledProcessError as e:
+                print(f"Error al obtener métricas del nodo {node}: {e.stderr}")
+    path = metrics_dir / "nodes"
+    archivos = os.listdir(path)
+    print(f"Recolección de métricas de pods completada y guardados en: {archivos}")
+    print("=========================================================")
+
+
+def main():
+    nodes = get_nodes()
+    if not nodes:
+        print("No se encontraron nodos.")
+    else:
+        print(f"Nodos encontrados: {', '.join(nodes)}")
+        print("=========================================================")
+        name = get_namespaces()
+        if not name:
+            print("No se encontraron namespaces.")
+        else:
+            print(f"Namespaces encontrados: {', '.join(name)}")
+            print("=========================================================")
+            collect_metrics__pods(name)
+            collect_metrics__nodes(nodes)
+
+
+if __name__ == "__main__":
+    main()

commit 4ca363f3069133417bf14323aceb96b8784175bd
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 17:12:52 2025 -0500

    fix(py): Actualiza metric_collector.py
---
 scripts/metric_collector/metric_collector.py | 51 +++++++++++++++++++++-------
 1 file changed, 39 insertions(+), 12 deletions(-)

diff --git a/scripts/metric_collector/metric_collector.py b/scripts/metric_collector/metric_collector.py
index ea498e0..12d83b7 100644
--- a/scripts/metric_collector/metric_collector.py
+++ b/scripts/metric_collector/metric_collector.py
@@ -14,13 +14,15 @@ import json
 
 
 def find_root_dir(target_folder_name):
-    '''
+    """
     Busca el directorio raíz del proyecto para el nombre de carpeta especificado.
-    '''
+    """
     current = Path(__file__).resolve()
     while current.name != target_folder_name:
         if current.parent == current:
-            raise FileNotFoundError(f"No se encontró el directorio '{target_folder_name}' hacia arriba desde {__file__}")
+            raise FileNotFoundError(
+                f"No se encontró el directorio '{target_folder_name}' hacia arriba desde {__file__}"
+            )
         current = current.parent
     return current
 
@@ -32,14 +34,29 @@ metrics_dir.mkdir(exist_ok=True)
 
 
 def get_namespaces():
-    namespaces = subprocess.run(["kubectl", "get", "namespaces", "-o", "name"], capture_output=True, text=True, check=True)
-    all_namespaces = [line.replace("namespace/", "") for line in namespaces.stdout.strip().splitlines()]
+    namespaces = subprocess.run(
+        ["kubectl", "get", "namespaces", "-o", "name"],
+        capture_output=True,
+        text=True,
+        check=True,
+    )
+    all_namespaces = [
+        line.replace("namespace/", "")
+        for line in namespaces.stdout.strip().splitlines()
+    ]
     return all_namespaces
 
 
 def get_nodes():
-    nodes = subprocess.run(["kubectl", "get", "nodes", "-o", "name"], capture_output=True, text=True, check=True)
-    all_nodes = [line.replace("node/", "") for line in nodes.stdout.strip().splitlines()]
+    nodes = subprocess.run(
+        ["kubectl", "get", "nodes", "-o", "name"],
+        capture_output=True,
+        text=True,
+        check=True,
+    )
+    all_nodes = [
+        line.replace("node/", "") for line in nodes.stdout.strip().splitlines()
+    ]
     return all_nodes
 
 
@@ -48,11 +65,15 @@ def collect_metrics__pods(namespaces):
     pods_dir.mkdir(exist_ok=True)
     print("Recolectando métricas de todos los pods...")
     for names in namespaces:
-        with open(pods_dir / f"{names}_metrics.csv", "a", encoding="utf-8") as pod_metrics_file:
+        with open(
+            pods_dir / f"{names}_metrics.csv", "a", encoding="utf-8"
+        ) as pod_metrics_file:
             try:
                 metrics_result = subprocess.run(
                     ["kubectl", "top", "pods", "-n", names],
-                    capture_output=True, text=True, check=True
+                    capture_output=True,
+                    text=True,
+                    check=True,
                 )
                 pod_metrics_file.write(metrics_result.stdout)
                 lines = metrics_result.stdout.strip().split("\n")
@@ -68,7 +89,9 @@ def collect_metrics__pods(namespaces):
                     with open(json_path, "w", encoding="utf-8") as jf:
                         json.dump(metrics, jf, indent=2)
             except subprocess.CalledProcessError as e:
-                print(f"Error al obtener métricas de los pods en el namespace {names}: {e.stderr}")
+                print(
+                    f"Error al obtener métricas de los pods en el namespace {names}: {e.stderr}"
+                )
     path = metrics_dir / "pods"
     archivos = os.listdir(path)
     print(f"Recolección de métricas de pods completada y guardados en: {archivos}")
@@ -80,11 +103,15 @@ def collect_metrics__nodes(nodes):
     nodes_dir.mkdir(exist_ok=True)
     print("Recolectando métricas de todos los nodos...")
     for node in nodes:
-        with open(nodes_dir / f"{node}_metrics.csv", "a", encoding="utf-8") as node_metrics_file:
+        with open(
+            nodes_dir / f"{node}_metrics.csv", "a", encoding="utf-8"
+        ) as node_metrics_file:
             try:
                 metrics_result = subprocess.run(
                     ["kubectl", "top", "nodes"],
-                    capture_output=True, text=True, check=True
+                    capture_output=True,
+                    text=True,
+                    check=True,
                 )
                 node_metrics_file.write(metrics_result.stdout)
                 lines = metrics_result.stdout.strip().split("\n")

commit f7d211838587042f29f386edea0b1b173ab033b0
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 17:14:44 2025 -0500

    fix(py): Actualiza información de ubicación de log_collector
---
 tests/test_collector_log.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/tests/test_collector_log.py b/tests/test_collector_log.py
index a4c872f..9c2c96f 100644
--- a/tests/test_collector_log.py
+++ b/tests/test_collector_log.py
@@ -1,6 +1,6 @@
 import pytest
 import subprocess
-from scripts.log_collector import get_pods, collect_logs, get_events
+from scripts.log_collector.log_collector import get_pods, collect_logs, get_events
 
 namespace = "default"
 

commit ee35498e4da11c7bef1ca3cef6711d786fdb4d68
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 17:17:19 2025 -0500

    fix(py): Actualiza ubicación del directorio raiz
---
 scripts/log_collector/log_collector.py       |  2 +-
 scripts/metric_collector/metric_collector.py |  2 +-
 tests/test_collector_log.py                  | 10 ++--------
 3 files changed, 4 insertions(+), 10 deletions(-)

diff --git a/scripts/log_collector/log_collector.py b/scripts/log_collector/log_collector.py
index 2107216..ab4f1f1 100644
--- a/scripts/log_collector/log_collector.py
+++ b/scripts/log_collector/log_collector.py
@@ -18,7 +18,7 @@ def find_root_dir(target_folder_name):
 namespace = sys.argv[1] if len(sys.argv) > 1 else "default"
 
 
-root_dir = find_root_dir("test-repo-pc4")
+root_dir = find_root_dir("Proyecto7-PC4")
 
 
 logs_dir = root_dir / "logs"
diff --git a/scripts/metric_collector/metric_collector.py b/scripts/metric_collector/metric_collector.py
index 12d83b7..f0948a4 100644
--- a/scripts/metric_collector/metric_collector.py
+++ b/scripts/metric_collector/metric_collector.py
@@ -27,7 +27,7 @@ def find_root_dir(target_folder_name):
     return current
 
 
-root_dir = find_root_dir("test-repo-pc4")
+root_dir = find_root_dir("Proyecto7-PC4")
 
 metrics_dir = root_dir / "metrics"
 metrics_dir.mkdir(exist_ok=True)
diff --git a/tests/test_collector_log.py b/tests/test_collector_log.py
index 9c2c96f..2b177f0 100644
--- a/tests/test_collector_log.py
+++ b/tests/test_collector_log.py
@@ -29,10 +29,7 @@ def test_collect_logs_xfail_and_fail():
         pytest.xfail("No hay pods disponibles en el namespace indicado")
 
     collect_logs(pods[0], namespace=namespace2)
-    subprocess.run(
-        ["rm", "-r", "logs"],
-        capture_output=True, text=True, check=True
-    )
+    subprocess.run(["rm", "-r", "logs"], capture_output=True, text=True, check=True)
 
 
 @pytest.mark.xfail(reason="Algún pod no está disponible")
@@ -42,7 +39,4 @@ def test_collect_logs_xfail_not_fail():
         pytest.xfail("No hay pods disponibles en el namespace indicado")
 
     collect_logs(pods[0], namespace=namespace2)
-    subprocess.run(
-        ["rm", "-r", "logs"],
-        capture_output=True, text=True, check=True
-    )
+    subprocess.run(["rm", "-r", "logs"], capture_output=True, text=True, check=True)

commit cd33380b5afedd4085fc23fc4e2bf06e9e6520b2
Merge: d74dd54 ee35498
Author: Christian Luna Jaramillo <65150753+Chriss5-2@users.noreply.github.com>
Date:   Sat Jun 28 17:20:27 2025 -0500

    Merge pull request #21 from grupo10-CC3S2/feature/script/metric-collector
    
    Implementación de metric_collector

commit a406f5dfa3d4292bc1306c92c22bfd5e8f6e25cd
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Sat Jun 28 17:25:30 2025 -0500

    feat(py): Añadir metric_visualizar.py con documentación
---
 scripts/metric_collector/README-visualizer.md |  90 +++++++++++++++++
 scripts/metric_collector/metric_visualizer.py | 138 ++++++++++++++++++++++++++
 2 files changed, 228 insertions(+)

diff --git a/scripts/metric_collector/README-visualizer.md b/scripts/metric_collector/README-visualizer.md
new file mode 100644
index 0000000..0251228
--- /dev/null
+++ b/scripts/metric_collector/README-visualizer.md
@@ -0,0 +1,90 @@
+# Visualización de métricas
+
+## Instalar metrics-server
+kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
+
+
+En caso ejecutemos la línea "kubectl top pods -n default" que indique algo como `API no disponible` lo que haremos será
+
+### 1.- kubectl get pods -n kube-system
+
+Y verificar que existe un pods llamado metric-server-<numero>-<codigo>
+
+Si verificamos eso, guardamos el nombre del pods, y editaremos su archivo
+
+```bash
+kubectl edit deployment metrics-server -n kube-system
+```
+Esto nos abrirá un editor, y cuando haga esto, buscamos lo siguiente:
+```bash
+containers:
+    - args:
+        - --cert-dir=/tmp
+        - --secure-port=10250
+        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
+        - --kubelet-use-node-status-port
+        - --metric-resolution=15s
+```
+Cuando encontremos eso, lo que haremos será agregar la siguiente línea
+```bash
+        - --kubelet-insecure-tls
+```
+**Ojo** Tener cuidado con los espacios
+
+Luego guardamos el editor, cerramos el archivo
+### Mal
+En caso hayamos editado mal nos aparecerá algo así cuando guardemos el archivo
+```bash
+error: deployments.apps "metrics-server" is invalid
+```
+Y nos abrirá otro editor
+
+### Bien
+En caso haberlo hecho bien, nos aparecerá este mensaje
+```bash
+deployment.apps/metrics-server edited
+```
+
+Ahora con esto, ya podemos ejecutar el comando
+
+```bash
+kubectl top pods -d default
+```
+
+Y nos mostrará el uso de Memory y CPU de los pods que existen en el namespace `default`
+
+Así que para la realización de obtención de métricas con `kubectl top` existen 3 formas:
+```bash
+##Comandos para obtener métricas de pods y nodes
+# Métricas de los pods en un namespace en específico
+kubectl top pods -n <namespace>
+
+# Métricas de los pods en el namespace por defecto
+kubectl top pods
+
+# Métricas de los nodes
+kubectl top nodes
+```
+
+# metric_visualizer.py
+## Vista general
+El script de `metric_visualizar.py` se encarga de generar archivos `.csv` donde guardará las métricas obtenidas mediante alguno de los comando anterior según el tipo de elemento que usemos, y de acuerdo a este archivo se encargará de:
+- Realizar una visualización simple y ordenada de los datos en la consola mediante el uso de tablas
+- Crear archivos `html` para la visualización mediante gráficos de barras
+
+## Función collect_metrics
+En el archivo `metric_visualizer.py` existen dos funciones de este tipo, uno para los pods `collect_metrics_pods` y otra para los nodos `collect_metric_nodes` esto lo realicé debido a que no se usa el mismo comando para ambos y preferí mantener un orden con la creación de archivos `csv` en vez de crear un `collect_metric_general` que ejecute ambos, así que estas funciones harán lo siguiente:
+> collect_metrics_pods(namespaces)
+- Esta función se encargará de revisar todos los `namespace` disponibles en el lista que solicita como argumento, de acuerdo a ello ejecutará el comando `kubectl top pods -d <namespace>` y guardará el resultado en el archivo `<namespace>.csv`, el csv lo creé para que luego sea posible leerlo con la libreria pandas, y de acuerdo a esto, realizar su gráfico de barras
+
+> collect_metrics_pods(nodes)
+- La función necesitará como argumento, una lista de los nodos disponibles, siendo esta verificación la principal ya que si no hay nodos, no existirá algún pod en el sistema, por lo que al asignarle el nombre del nodo, este ejecutará el comando `kubectl top nodes` y el resultado lo guardará en `<node>.csv`
+
+## Función clean_raw_metrics 
+Esta función se encargará de leer el archivo `csv` creado y de acuerdo a esto, con la libreria pandas, lo separará en columnas con el nombre que posee cada columna en el resultado del comando , para así manejar los datos como un DataFrame facilitando su limpieza y visualización posterior
+
+## Función show_console_table
+El objetivo de esta función es para cumplir con el primer requisito de la rúbrica para esta tarea, la cuál es de mostrar los datos en la consola pero de manera ordenada y simple, así que con la libreria tabulate, lo que realicé fue mostrar todos los datos de manera tabulada en la pantalla, haciendo que sea más entendible y fácil de leer al momento de ejecutar el script
+
+## Funcion generate_html_graph
+Esta función termina de cumplir el último objetivo de la tarea, la cuál es generar un archivo `html` donde sea posible su visualización, en un primer momento lo quise realizar de manera vertical, pero luego como hay una gran diferencia entre los datos de las columnas, había perdida de datos o mejor dicho, no se podía ver correctamente algunas barras, así que para esta función lo que hice fue que los gráficos de barras se muestren de manera horizontal, ya que así tendrá más tamaño y podrá verse el gráfico correctamente con todas las columnas que presentan los archivos `csv`
\ No newline at end of file
diff --git a/scripts/metric_collector/metric_visualizer.py b/scripts/metric_collector/metric_visualizer.py
new file mode 100644
index 0000000..00907ae
--- /dev/null
+++ b/scripts/metric_collector/metric_visualizer.py
@@ -0,0 +1,138 @@
+import os
+from pathlib import Path
+import sys
+import subprocess
+import pandas as pd
+from tabulate import tabulate
+import plotly.express as px
+
+# Comandos para obtener métricas de pods y nodes
+# 1.- kubectl top pods -n <namespace>
+# 2.- kubectl top pods
+# 3.- kubectl top nodes
+
+
+def find_root_dir(target_folder_name):
+    '''
+    Busca el directorio raíz del proyecto para el nombre de carpeta especificado.
+    '''
+    current = Path(__file__).resolve()
+    while current.name != target_folder_name:
+        if current.parent == current:
+            raise FileNotFoundError(f"No se encontró el directorio '{target_folder_name}' hacia arriba desde {__file__}")
+        current = current.parent
+    return current
+
+
+root_dir = find_root_dir("test-repo-pc4")
+
+metrics_dir = root_dir / "metrics"
+metrics_dir.mkdir(exist_ok=True)
+
+
+# Visualización de métricas
+def clean_raw_metrics_pods(pod_path):
+    df = pd.read_csv(pod_path, sep=r'\s+')
+    df.columns = ["POD", "CPU_cores(m)", "MEM_bytes(Mi)"]
+    df["CPU_cores(m)"] = df["CPU_cores(m)"].str.replace("m", "", regex=False).astype(int)
+    df["MEM_bytes(Mi)"] = df["MEM_bytes(Mi)"].str.replace("Mi", "", regex=False).astype(int)
+
+    return df
+
+
+def clean_raw_metrics_nodes(node_path):
+    df = pd.read_csv(node_path, sep=r'\s+')
+
+    df.columns = ["NODE", "CPU_cores(m)", "CPU_%", "MEM_bytes(Mi)", "MEM_%"]
+
+    df["CPU_cores(m)"] = df["CPU_cores(m)"].str.replace("m", "", regex=False).astype(str)
+    df["CPU_%"] = df["CPU_%"].str.replace("%", "", regex=False).astype(str)
+    df["MEM_bytes(Mi)"] = df["MEM_bytes(Mi)"].str.replace("Mi", "", regex=False).astype(str)
+    df["MEM_%"] = df["MEM_%"].str.replace("%", "", regex=False).astype(str)
+
+    return df
+
+
+def show_console_table(df, name):
+    print(f"\n=== Tabla resumida de métricas de {name} ===")
+    print(tabulate(df, headers='keys', tablefmt='fancy_grid'))
+
+
+# Ingresar pods or nodes
+def visualize_metrics_console():
+    path = metrics_dir
+    folders = os.listdir(path)
+    for folder in folders:
+        files_path = path / folder
+        archivos = os.listdir(files_path)
+        for file in archivos:
+            if not file.endswith(".csv"):
+                continue
+            else:
+                if folder == "pods":
+                    with open(files_path / file, "r", encoding="utf-8") as f:
+                        read = f.read()
+                    if not read:
+                        print(f"Las métricas de {file} no están disponibles.")
+                    else:
+                        df = clean_raw_metrics_pods(files_path / file)
+                        show_console_table(df, file)
+                        generate_html_graph_pods(df, files_path / f"{file.split('.')[0]}.html", f"{file.split('.')[0]}.html")
+                elif folder == "nodes":
+                    with open(files_path / file, "r", encoding="utf-8") as f:
+                        read = f.read()
+                    if not read:
+                        print(f"Las métricas de {file} no están disponibles.")
+                    else:
+                        df = clean_raw_metrics_nodes(files_path / file)
+                        show_console_table(df, file)
+                        generate_html_graph_nodes(df, files_path / f"{file.split('.')[0]}.html", f"{file.split('.')[0]}.html")
+
+
+def generate_html_graph_pods(df, output_path, name):
+    df_long = df.melt(id_vars="POD", value_vars=["CPU_cores(m)", "MEM_bytes(Mi)"], var_name="Recurso", value_name="Valor")
+
+    df_long["Recurso"] = df_long["Recurso"].replace({
+        "CPU_cores(m)": "CPU (m)",
+        "MEM_bytes(Mi)": "Memoria (Mi)"
+    })
+
+    fig = px.bar(df_long, y="POD", x="Valor", color="Recurso", barmode="group", orientation="h", title="Uso de CPU y Memoria por Pod")
+    fig.update_traces(texttemplate='%{x}', textposition='outside')
+    fig.write_html(output_path)
+    print(f"\nGráfico HTML guardado en: {name}")
+
+
+def generate_html_graph_nodes(df, output_path, name):
+    df["CPU_cores(m)"] = df["CPU_cores(m)"].astype(float)
+    df["CPU_%"] = df["CPU_%"].astype(float)
+    df["MEM_bytes(Mi)"] = df["MEM_bytes(Mi)"].astype(float)
+    df["MEM_%"] = df["MEM_%"].astype(float)
+
+    df_long = df.melt(
+        id_vars="NODE",
+        value_vars=["CPU_cores(m)", "CPU_%", "MEM_bytes(Mi)", "MEM_%"],
+        var_name="Recurso",
+        value_name="Valor"
+    )
+
+    df_long["Recurso"] = df_long["Recurso"].replace({
+        "CPU_cores(m)": "CPU (m)",
+        "CPU_%": "CPU (%)",
+        "MEM_bytes(Mi)": "Memoria (Mi)",
+        "MEM_%": "Memoria (%)"
+    })
+
+    fig = px.bar(df_long, y="NODE", x="Valor", color="Recurso", barmode="group", orientation="h", title="Uso de Recursos por Nodo (CPU y Memoria)")
+
+    fig.update_traces(texttemplate='%{x}', textposition='outside')
+    fig.write_html(output_path)
+    print(f"\nGráfico HTML guardado en: {name}")
+
+
+def main():
+    visualize_metrics_console()
+
+
+if __name__ == "__main__":
+    main()

commit 7a68c25e9cf9b2f38b225616149b79d55665e0ae
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Sat Jun 28 17:26:18 2025 -0500

    docs(gitignote): Actualizar gitignore para excluir debug.log
---
 .gitignore | 1 +
 1 file changed, 1 insertion(+)

diff --git a/.gitignore b/.gitignore
index ceb5ae8..40c0613 100644
--- a/.gitignore
+++ b/.gitignore
@@ -12,3 +12,4 @@ env/
 venv/
 
 
+debug.log
\ No newline at end of file

commit 755f3d16dcc9487e1f52416cafcd8434167a72d3
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Sat Jun 28 17:29:30 2025 -0500

    fix(py): Actualizar ubicación de directorio raíz
---
 scripts/metric_collector/metric_visualizer.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/scripts/metric_collector/metric_visualizer.py b/scripts/metric_collector/metric_visualizer.py
index 00907ae..e627863 100644
--- a/scripts/metric_collector/metric_visualizer.py
+++ b/scripts/metric_collector/metric_visualizer.py
@@ -24,7 +24,7 @@ def find_root_dir(target_folder_name):
     return current
 
 
-root_dir = find_root_dir("test-repo-pc4")
+root_dir = find_root_dir("Proyecto7-PC4")
 
 metrics_dir = root_dir / "metrics"
 metrics_dir.mkdir(exist_ok=True)

commit 956e81f0b37431c1a00c21bde88a012f941198b7
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Sat Jun 28 17:31:29 2025 -0500

    feat(py): Añadir pruebas para metric_collector.py y metric_visualizer.py
---
 tests/test_metric_visualizer.py | 32 ++++++++++++++++++++++++++++++++
 1 file changed, 32 insertions(+)

diff --git a/tests/test_metric_visualizer.py b/tests/test_metric_visualizer.py
new file mode 100644
index 0000000..21fbb90
--- /dev/null
+++ b/tests/test_metric_visualizer.py
@@ -0,0 +1,32 @@
+import pytest
+from scripts.metric_collector import metric_collector
+from scripts.metric_collector import metric_visualizer
+
+
+root_dir = metric_visualizer.find_root_dir("Proyecto7-PC4")
+
+
+def setup_module(module):
+    # Se ejecuta una vez antes de cualquier test en este archivo
+    print("\n[setup] Ejecutando dependencias...")
+    metric_collector.main()  # si aplica
+    metric_visualizer.main()  # o alguna función que prepare el entorno
+
+
+@pytest.mark.xfail(reason="El directorio no existe")
+def test_not_fing_root_dir():
+    assert metric_visualizer.find_root_dir("non_existent_dir")
+
+
+def test_find_root_dir():
+    root = metric_visualizer.find_root_dir("Proyecto7-PC4")
+    assert root.is_dir()
+
+
+def test_clean_raw_metrics_pods():
+    pod_path = root_dir / "metrics" / "pods" / "default_metrics.csv"
+    df = metric_visualizer.clean_raw_metrics_pods(pod_path)
+    assert not df.empty
+    assert "POD" in df.columns
+    assert "CPU_cores(m)" in df.columns
+    assert "MEM_bytes(Mi)" in df.columns

commit 4404b052d5d0917c69a35ed9c640eccf2d9656d1
Merge: cd33380 956e81f
Author: Jesus Diego Osorio Tello <130506742+JesusOsorio-19@users.noreply.github.com>
Date:   Sat Jun 28 17:36:35 2025 -0500

    Merge pull request #22 from grupo10-CC3S2/feature/scripts/metric_visualizer
    
    Visualización simple y ordenada de las métricas de nodos y pods

commit ff2f83f5c0606a202bc4933b6ad6c748128fe272
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 17:47:46 2025 -0500

    feat(make): fix variable url
---
 Makefile                | 12 ++++++++----
 flux-gitrepository.yaml |  2 +-
 2 files changed, 9 insertions(+), 5 deletions(-)

diff --git a/Makefile b/Makefile
index 3100890..a1b9ba2 100644
--- a/Makefile
+++ b/Makefile
@@ -1,4 +1,4 @@
-REPO = "https://github.com/grupo10-CC3S2/test-repo-pc4"
+REPO = "https://github.com/grupo10-CC3S2/Proyecto7-PC4"
 
 setup-v1:
 	docker build -t timeserver:v1 app
@@ -12,7 +12,8 @@ setup-v2:
 	kubectl get pods
 
 teardown:
-	kubectl delete -f k8s/
+	flux suspend kustomization kustomization-github
+	kubectl delete all --all --namespace=default --force --grace-period=0
 	docker image rm timeserver:v1
 	docker image rm timeserver:v2
 
@@ -25,7 +26,7 @@ flux-init:
 flux-creater:
 	flux create source git repo-github --url=$(REPO) --branch=main --interval=30s --export > ./flux-gitrepository.yaml
 	kubectl apply -f ./flux-gitrepository.yaml
-
+	
 flux-createk:
 	flux create kustomization kustomization-github --source=GitRepository/repo-github --path="./k8s" --prune=true --interval=30s --export > ./flux-kustomization.yaml
 	kubectl apply -f ./flux-kustomization.yaml
@@ -36,5 +37,8 @@ flux-getk:
 flux-watchk:
 	flux get kustomizations --watch
 
+flux-suspend:
+	flux suspend kustomization kustomization-github
+
 pod-images:
-	kubectl get pods -n default -l pod=timeserver-pod -o jsonpath='{.items[*].spec.containers[*].image}'
\ No newline at end of file
+	kubectl get pods --namespace=default -o json | jq '.items[].spec.containers[] | {pod: .name, container_name: .name, image: .image}'
\ No newline at end of file
diff --git a/flux-gitrepository.yaml b/flux-gitrepository.yaml
index ce1e66b..da2aacb 100644
--- a/flux-gitrepository.yaml
+++ b/flux-gitrepository.yaml
@@ -8,4 +8,4 @@ spec:
   interval: 30s
   ref:
     branch: main
-  url: https://github.com/grupo10-CC3S2/test-repo-pc4
+  url: https://github.com/grupo10-CC3S2/Proyecto7-PC4

commit a04ec92ecf9d7c90821274c42e439605bfc03001
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 20:04:06 2025 -0500

    feat(yaml): actualiza version de imagen
---
 k8s/deploy.yaml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/k8s/deploy.yaml b/k8s/deploy.yaml
index 67ede29..098e2a4 100644
--- a/k8s/deploy.yaml
+++ b/k8s/deploy.yaml
@@ -15,5 +15,5 @@ spec:
     spec:
       containers:
       - name: timeserver-container
-        image: timeserver:v1
+        image: timeserver:v2
         imagePullPolicy: Never
\ No newline at end of file

commit 7d9a8b4e1aff7871f72b067cb8653d17421116b5
Merge: 4404b05 a04ec92
Author: Jesus Diego Osorio Tello <130506742+JesusOsorio-19@users.noreply.github.com>
Date:   Sat Jun 28 20:08:21 2025 -0500

    Merge pull request #20 from grupo10-CC3S2/feature/gitops-flux
    
    Feature/gitops flux

commit 35b3919a64fcfbf5580f94347b579cb794418f26
Author: Diego <jesustello192002@gmail.com>
Date:   Sat Jun 28 20:14:29 2025 -0500

    docs(md): Añade link del video del sprint 2
---
 videos/README.md | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/videos/README.md b/videos/README.md
index 7816260..7dfa9e4 100644
--- a/videos/README.md
+++ b/videos/README.md
@@ -8,4 +8,8 @@
 
 ## Sprint-1
 
-[Video Sprint 1](https://drive.google.com/file/d/1tIrF-FU1v7B8dVrN-dbGRqnPmfwTTgwl/view?usp=drive_link)
\ No newline at end of file
+[Video Sprint 1](https://drive.google.com/file/d/1tIrF-FU1v7B8dVrN-dbGRqnPmfwTTgwl/view?usp=drive_link)
+
+## Sprint-2
+
+[Video Sprint 2](https://drive.google.com/file/d/14Z8FHLXlaGn3w7PuGp_7PCWK98kEiZxH/view?usp=drive_link)

commit aed328bf9c1ac403fc821afe6e759cb51dd1b56a
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 23:51:44 2025 -0500

    feat(py): agrega ruta de health
---
 app/server.py | 7 ++++++-
 1 file changed, 6 insertions(+), 1 deletion(-)

diff --git a/app/server.py b/app/server.py
index 129c4f7..c06fb6b 100644
--- a/app/server.py
+++ b/app/server.py
@@ -1,4 +1,4 @@
-from flask import Flask, Response
+from flask import Flask, Response, jsonify
 from datetime import datetime, timezone
 from zoneinfo import ZoneInfo
 from logger_service import start_background_logging, logger
@@ -19,6 +19,11 @@ def get_current_time():
     return Response(response_string, mimetype='text/plain')
 
 
+@app.route("/health")
+def health_check():
+    return jsonify({"status": "ok"})
+
+
 if __name__ == "__main__":
     start_background_logging()
     logger.info("Flask server starting on 0.0.0.0:80")

commit 3eb65faf39c9701fe5660341bc4313cd7e714ade
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sat Jun 28 23:52:10 2025 -0500

    feat(yaml): actualiza version de imagen a v3
---
 k8s/deploy.yaml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/k8s/deploy.yaml b/k8s/deploy.yaml
index 098e2a4..e19f372 100644
--- a/k8s/deploy.yaml
+++ b/k8s/deploy.yaml
@@ -15,5 +15,5 @@ spec:
     spec:
       containers:
       - name: timeserver-container
-        image: timeserver:v2
+        image: timeserver:v3
         imagePullPolicy: Never
\ No newline at end of file

commit 6de23196d068f966ceb4243eea30451e180be461
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sun Jun 29 00:39:23 2025 -0500

    test(py): agrega conftest con fixtures de kubernetes para probar api y recursos
---
 tests/conftest.py | 70 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 70 insertions(+)

diff --git a/tests/conftest.py b/tests/conftest.py
new file mode 100644
index 0000000..8fad703
--- /dev/null
+++ b/tests/conftest.py
@@ -0,0 +1,70 @@
+import pytest
+from kubernetes import config, client
+
+NAMESPACE = "default"
+DEPLOYMENT_NAME = "timeserver"
+SERVICE_NAME = "timeserver"
+POD_LABEL_SELECTOR = "pod=timeserver-pod"
+
+
+@pytest.fixture(scope="session")
+def resource_names():
+    return {
+        "namespace": NAMESPACE,
+        "deployment": DEPLOYMENT_NAME,
+        "service": SERVICE_NAME,
+        "pod_label_selector": POD_LABEL_SELECTOR
+    }
+
+
+@pytest.fixture(scope="session")
+def app_service_url():
+    return "http://localhost:80"
+
+
+@pytest.fixture(scope="session")
+def kube_api_client():
+    try:
+        config.load_incluster_config()
+    except config.ConfigException:
+        config.load_kube_config()
+    return client.AppsV1Api()
+
+
+@pytest.fixture(scope="session")
+def kube_core_api_client():
+    try:
+        config.load_incluster_config()
+    except config.ConfigException:
+        config.load_kube_config()
+    return client.CoreV1Api()
+
+
+@pytest.fixture(scope="module")
+def timeserver_deployment(kube_api_client: client.AppsV1Api):
+    try:
+        return kube_api_client.read_namespaced_deployment(
+            name=DEPLOYMENT_NAME, namespace=NAMESPACE
+        )
+    except Exception as e:
+        pytest.fail(f"Fallo al obtener el Deployment '{DEPLOYMENT_NAME}'. Error: {e}")
+
+
+@pytest.fixture(scope="module")
+def timeserver_service(kube_core_api_client: client.CoreV1Api):
+    try:
+        return kube_core_api_client.read_namespaced_service(
+            name=SERVICE_NAME, namespace=NAMESPACE
+        )
+    except Exception as e:
+        pytest.fail(f"Fallo al encontrar el Service '{SERVICE_NAME}'. Error: {e}")
+
+@pytest.fixture(scope="module")
+def timeserver_pods(kube_core_api_client: client.CoreV1Api):
+    try:
+        pods = kube_core_api_client.list_namespaced_pod(
+            namespace=NAMESPACE, label_selector=POD_LABEL_SELECTOR
+        )
+        return pods.items
+    except Exception as e:
+        pytest.fail(f"Fallo al listar los pods. Error: {e}")

commit 74bca3831a117401a66053c66ea8a551f508e957
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sun Jun 29 00:39:32 2025 -0500

    test(py): agrega test de health de app
---
 tests/test_health_api.py | 48 ++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 48 insertions(+)

diff --git a/tests/test_health_api.py b/tests/test_health_api.py
new file mode 100644
index 0000000..df69515
--- /dev/null
+++ b/tests/test_health_api.py
@@ -0,0 +1,48 @@
+import requests
+import pytest
+import time
+
+
+def test_health_ok(app_service_url: str):
+    health_check_url = f"{app_service_url}/health"
+    try:
+        response = requests.get(health_check_url, timeout=5)
+        response.raise_for_status()
+
+        assert response.json() == {"status": "ok"}, \
+            "El cuerpo de la respuesta de /health no es el esperado."
+
+    except requests.exceptions.RequestException as e:
+        pytest.fail(f"No se pudo conectar con el endpoint /health. Error: {e}")
+
+
+def test_content_endpoint(app_service_url: str):
+    try:
+        response = requests.get(app_service_url, timeout=5)
+        response.raise_for_status()
+
+        response_text = response.text
+        assert "UTC" in response_text, "La respuesta no contiene la hora en UTC."
+        assert "Lima" in response_text, "La respuesta no contiene la hora de Lima."
+
+    except requests.exceptions.RequestException as e:
+        pytest.fail(f"No se pudo conectar con el endpoint principal ('/'). Error: {e}")
+
+
+def test_health_performance(app_service_url: str):
+    health_check_url = f"{app_service_url}/health"
+
+    try:
+        start_time = time.time()
+        response = requests.get(health_check_url, timeout=5)
+        end_time = time.time()
+
+        response.raise_for_status()
+
+        response_time = end_time - start_time
+
+        assert response_time < 1.0, \
+            f"El tiempo de respuesta del health check es demasiado alto: {response_time:.2f}s"
+
+    except requests.exceptions.RequestException as e:
+        pytest.fail(f"No se pudo conectar con el endpoint /health. Error: {e}")

commit a7806e61e612658b102fc2061626735c8791bff2
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sun Jun 29 00:39:40 2025 -0500

    test(py): agrega test de health de infra
---
 tests/test_health_infra.py | 23 +++++++++++++++++++++++
 1 file changed, 23 insertions(+)

diff --git a/tests/test_health_infra.py b/tests/test_health_infra.py
new file mode 100644
index 0000000..1370ffa
--- /dev/null
+++ b/tests/test_health_infra.py
@@ -0,0 +1,23 @@
+def test_deployment_available(timeserver_deployment):
+    status = timeserver_deployment.status
+    spec = timeserver_deployment.spec
+
+    assert status.available_replicas == spec.replicas, \
+        f"El numero de replicas disponibles ({status.available_replicas}) no coincide con el deseado ({spec.replicas})."
+
+    assert status.ready_replicas == spec.replicas, \
+        f"El numero de replicas listas ({status.ready_replicas}) no coincide con el deseado ({spec.replicas})."
+
+
+def test_service_exists(timeserver_service, resource_names):
+    assert timeserver_service is not None
+    assert timeserver_service.metadata.name == resource_names["service"]
+
+
+def test_pods_running(timeserver_pods, resource_names):
+    assert timeserver_pods is not None, "No se encontraron pods."
+
+    assert len(timeserver_pods) == 3
+
+    for pod in timeserver_pods:
+        assert pod.status.phase == "Running", f"El pod {pod.metadata.name} no esta en estado 'Running'."

commit 32010034d1f8a4f44dd94434356e37400cde6603
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sun Jun 29 02:03:26 2025 -0500

    test(py): agrega conftest con fixtures para test e2e
---
 tests/conftest.py | 49 +++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 49 insertions(+)

diff --git a/tests/conftest.py b/tests/conftest.py
index 8fad703..1976ca9 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -1,5 +1,7 @@
 import pytest
 from kubernetes import config, client
+import shutil
+from pathlib import Path
 
 NAMESPACE = "default"
 DEPLOYMENT_NAME = "timeserver"
@@ -17,6 +19,11 @@ def resource_names():
     }
 
 
+@pytest.fixture(scope="session")
+def project_root():
+    return Path(__file__).parent.parent
+
+
 @pytest.fixture(scope="session")
 def app_service_url():
     return "http://localhost:80"
@@ -59,6 +66,7 @@ def timeserver_service(kube_core_api_client: client.CoreV1Api):
     except Exception as e:
         pytest.fail(f"Fallo al encontrar el Service '{SERVICE_NAME}'. Error: {e}")
 
+
 @pytest.fixture(scope="module")
 def timeserver_pods(kube_core_api_client: client.CoreV1Api):
     try:
@@ -68,3 +76,44 @@ def timeserver_pods(kube_core_api_client: client.CoreV1Api):
         return pods.items
     except Exception as e:
         pytest.fail(f"Fallo al listar los pods. Error: {e}")
+
+
+@pytest.fixture(scope="function")
+def observability_dirs(project_root):
+    dirs = {
+        "metrics": project_root / "metrics",
+        "logs": project_root / "logs",
+        "alerts": project_root / "alerts"
+    }
+    for path in dirs.values():
+        if path.exists():
+            shutil.rmtree(path)
+        path.mkdir(parents=True, exist_ok=True)
+    yield dirs
+    for path in dirs.values():
+        if path.exists():
+            shutil.rmtree(path)
+
+
+@pytest.fixture(scope="function")
+def run_metric_collector(observability_dirs):
+    from scripts.metric_collector import metric_collector
+    try:
+        metric_collector.main()
+        return observability_dirs["metrics"]
+    except Exception as e:
+        pytest.fail(f"La recoleccion de metricas fallo: {e}")
+
+
+@pytest.fixture(scope="function")
+def run_log_collector(observability_dirs, timeserver_pods):
+    from scripts.log_collector import log_collector
+    if not timeserver_pods:
+        pytest.skip("No se encontraron pods para la recoleccion de logs.")
+
+    pod_names = [p.metadata.name for p in timeserver_pods]
+    try:
+        log_collector.collect_logs(pod_names, NAMESPACE)
+        return observability_dirs["logs"]
+    except Exception as e:
+        pytest.fail(f"La recoleccion de logs fallo: {e}")

commit d52fb9c6ed34f716333ac4333ad09ffa01d3b6c5
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Sun Jun 29 02:03:48 2025 -0500

    test(py): agrega test e2e para logs y metricas
---
 tests/test_e2e.py | 39 +++++++++++++++++++++++++++++++++++++++
 1 file changed, 39 insertions(+)

diff --git a/tests/test_e2e.py b/tests/test_e2e.py
new file mode 100644
index 0000000..e3538b6
--- /dev/null
+++ b/tests/test_e2e.py
@@ -0,0 +1,39 @@
+def test_metric_dirs(run_metric_collector):
+    metrics_dir = run_metric_collector
+    assert metrics_dir.exists(), "El directorio principal de métricas no fue creado."
+    pods_dir = metrics_dir / "pods"
+    nodes_dir = metrics_dir / "nodes"
+    assert pods_dir.exists(), "El directorio de métricas de pods no fue creado."
+    assert nodes_dir.exists(), "El directorio de métricas de nodos no fue creado."
+
+
+def test_metric_files(run_metric_collector):
+    metrics_dir = run_metric_collector
+
+    csv_files = list(metrics_dir.rglob("*.csv"))
+    json_files = list(metrics_dir.rglob("*.json"))
+
+    assert len(csv_files) > 0, "No se generaron archivos CSV de métricas."
+    assert len(json_files) > 0, "No se generaron archivos JSON de métricas."
+
+
+def test_log_files(run_log_collector):
+    logs_dir = run_log_collector
+    assert logs_dir.exists(), "El directorio de logs no fue creado."
+
+    main_log_file = logs_dir / "all_pods.log"
+    individual_logs = [f for f in logs_dir.glob("*.log") if f.name != "all_pods.log"]
+
+    assert main_log_file.exists(), "El archivo de log principal no fue creado."
+    assert len(individual_logs) > 0, "No se crearon logs individuales para los pods."
+
+
+def test_log_not_empty(run_log_collector):
+    main_log_file = run_log_collector / "all_pods.log"
+
+    with open(main_log_file, 'r', encoding='utf-8') as f:
+        content = f.read()
+        print(f"contenido {content}")
+
+    assert len(content) > 0, "El archivo de logs principal está vacío."
+    assert "Logs del pod:" in content, "El formato esperado no se encontró en el log."

commit ccc1795a5c06d65cf7d5cd4ca58804e4f3d1c7ce
Merge: e71cb53 35b3919
Author: Alex Vega <91773368+axvg@users.noreply.github.com>
Date:   Sun Jun 29 11:20:22 2025 -0500

    Merge pull request #23 from grupo10-CC3S2/develop
    
    Sprint2 concluido

commit 3e85acd154d780291329b2f071492d36892815dd
Author: Diego <jesustello192002@gmail.com>
Date:   Sun Jun 29 20:35:13 2025 -0500

    feat(chaos): Añade script chaos-test que simula la eliminación de un pod, detecta el problema y genera una alerta
---
 scripts/chaos_test/README-chaos.md  |  50 +++++++++
 scripts/chaos_test/chaos_testing.py | 209 ++++++++++++++++++++++++++++++++++++
 scripts/chaos_test/imgs/1.png       | Bin 0 -> 16723 bytes
 scripts/chaos_test/imgs/2.png       | Bin 0 -> 81316 bytes
 scripts/chaos_test/imgs/3.png       | Bin 0 -> 17147 bytes
 scripts/chaos_test/imgs/4.png       | Bin 0 -> 38345 bytes
 scripts/chaos_test/imgs/5.png       | Bin 0 -> 59982 bytes
 7 files changed, 259 insertions(+)

diff --git a/scripts/chaos_test/README-chaos.md b/scripts/chaos_test/README-chaos.md
new file mode 100644
index 0000000..24e371f
--- /dev/null
+++ b/scripts/chaos_test/README-chaos.md
@@ -0,0 +1,50 @@
+# Chaos Testing Minimal
+
+Implementamos `chaos_testing.py` que simula la eliminación de un Pod y observa cómo se detecta el problema generando alertas.
+
+## Este script tiene como componentes:
+
+- Clase MinimalChaosTest, que maneja todo el flujo de chaos testing.
+- Cuenta con un sistema de alertas que detecta y registra eventos durante el proceso.
+- Selecciona aleatoriamente un pod que será eliminado controladamente.
+- Un monitoreo de recuperación automática.
+- Para más orden también genera un reporte en formato .json.
+
+## Ahora también tenemos algunos detalles que tenemos que tener en cuenta.
+
+Hay alertas, como las siguientes, que no se detectan.
+
+![](imgs/4.png)
+
+Esto se debe a que Kubernetes es extremadamente rápido para generar nuevamente un pod. A pesar de que tenemos un intervalo de checkeo de 1 segundo, `ContainerCreating` dura menos de un segundo en Docker Desktop por lo cual no se detectan estas dos alertas. Sin embargo, no es un gran problema porque finalmente podemos visualizar el pod nuevo creado con el comando `kubectl get pod`.
+
+## Uso del script
+
+- Ejecutamos el script. Para esto debemos tener Kubernetes funcionando y también al menos 2 pods `timeserver` en status Running.
+
+    ```py
+    python scripts/chaos_test/chaos_testing.py
+    ```
+
+- Esto nos generará  `scripts/chaos_test/reports/chaos_testing_report.json`
+
+## Ejemplo de uso
+
+1. Visualizamos que pods tenemos antes de ejecutar nuestro script.
+    
+    ![](imgs/1.png)
+
+2. Ejecutamos nuestro script, vemos los problemas generados y que alarmas se detectan.
+
+    ![](imgs/2.png)
+
+    Acá es donde debería mostrarse las alertas mencionadas, luego de la alerta _PROBLEMA DETECTADO: Pod timeserver-7c9445b569-rzn6t ya no existe en el cluster_, pero vemos que inmediantamente, a pesar de la confirmación de la eliminación del pod, está corriendo un nuevo pod.
+
+3. Archivo .json generado.
+
+    ![](imgs/5.png)
+    Vemos que nos muestra las 4 alertas detectadas.
+
+4. Vemos un nuevo pod en status running.
+
+    ![](imgs/3.png)
diff --git a/scripts/chaos_test/chaos_testing.py b/scripts/chaos_test/chaos_testing.py
new file mode 100644
index 0000000..2d47e2a
--- /dev/null
+++ b/scripts/chaos_test/chaos_testing.py
@@ -0,0 +1,209 @@
+import subprocess
+import time
+import random
+import json
+import os
+
+
+class MinimalChaosTest:
+    def __init__(self, namespace="default", pod_selector="timeserver-pod"):
+        self.namespace = namespace
+        self.pod_selector = (
+            pod_selector  # Cambio: usar pod_selector en lugar de app_label
+        )
+        self.alerts = []
+
+        os.makedirs("scripts/chaos_test/reports", exist_ok=True)
+
+    def get_pods(self, verbose=True):
+        if verbose:
+            print(f"\nObteniendo pods con namespace {self.namespace}")
+        try:
+            cmd = [
+                "kubectl",
+                "get",
+                "pods",
+                "-n",
+                self.namespace,
+                "-l",
+                f"pod={self.pod_selector}",
+                "--no-headers",
+            ]
+            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
+
+            pods = []
+            for line in result.stdout.strip().splitlines():
+                parts = line.split()
+                pod_name = parts[0]
+                status = parts[2]
+                pods.append({"name": pod_name, "status": status})
+                if verbose:
+                    print(f"   Pod: {pod_name} - Status: {status}")
+
+            return pods
+        except subprocess.CalledProcessError as e:
+            self.generate_alert(f"ERROR: No se pudieron obtener pods: {e.stderr}")
+            return []
+
+    def generate_alert(self, message):
+        alert = {"message": message, "type": "chaos_testing_alert"}
+        self.alerts.append(alert)
+        print(f" ALERTA:\n {message}")
+        return alert
+
+    def simulate_pod_deletion(self):
+        print("\n" + "=" * 50)
+        print(" INICIANDO CHAOS TESTING MINIMAL")
+        print("=" * 50)
+
+        pods = self.get_pods()
+        running_pods = [p for p in pods if p["status"] == "Running"]
+
+        print(f" Pods encontrados: {len(pods)}")
+        print(f" Pods Running: {len(running_pods)}")
+
+        if len(running_pods) < 2:
+            self.generate_alert(
+                "ERROR: Se necesitan al menos 2 pods Running para chaos testing seguro"
+            )
+            return None
+
+        victim = random.choice(running_pods)
+        victim_name = victim["name"]
+
+        print(f"\n Pod seleccionado para eliminación: {victim_name}")
+        self.generate_alert(
+            f"CHAOS INICIADO: Pod {victim_name} seleccionado para eliminación"
+        )
+
+        try:
+            print(f" Eliminando pod {victim_name}...")
+            cmd = ["kubectl", "delete", "pod", victim_name, "-n", self.namespace]
+            subprocess.run(cmd, capture_output=True, text=True, check=True)
+
+            self.generate_alert(
+                f"POD ELIMINADO: {victim_name} ha sido eliminado exitosamente"
+            )
+            print(f" Pod {victim_name} eliminado")
+            return victim_name
+
+        except subprocess.CalledProcessError as e:
+            self.generate_alert(
+                f"ERROR: Falló eliminación de pod {victim_name}: {e.stderr}"
+            )
+            return None
+
+    def detect_problem(self, eliminated_pod, monitoring_duration=30):
+        print(
+            f"\n DETECTANDO PROBLEMA - Monitoreando por {monitoring_duration} segundos"
+        )
+        print("-" * 50)
+
+        start_time = time.time()
+        problem_detected = False
+        recovery_started = False
+        recovery_complete = False
+
+        initial_pod_count = len(self.get_pods(verbose=False))
+
+        while time.time() - start_time < monitoring_duration:
+            current_pods = self.get_pods(verbose=False)
+            elapsed_time = int(time.time() - start_time)
+
+            if elapsed_time % 10 == 0 and elapsed_time > 0:
+                print(f" Progreso: {elapsed_time}s - {len(current_pods)} pods activos")
+
+            eliminated_found = any(
+                pod["name"] == eliminated_pod for pod in current_pods
+            )
+
+            if not eliminated_found and not problem_detected:
+                self.generate_alert(
+                    f"PROBLEMA DETECTADO: Pod {eliminated_pod} ya no existe en el cluster"
+                )
+                problem_detected = True
+
+            creating_pods = [
+                p for p in current_pods if p["status"] == "ContainerCreating"
+            ]
+            if creating_pods and not recovery_started:
+                for pod in creating_pods:
+                    self.generate_alert(
+                        f"RECUPERACIÓN DETECTADA: Nuevo pod {pod['name']} siendo creado"
+                    )
+                recovery_started = True
+
+            running_count = len([p for p in current_pods if p["status"] == "Running"])
+            if (
+                running_count >= initial_pod_count
+                and recovery_started
+                and not recovery_complete
+            ):
+                self.generate_alert(
+                    f"RECUPERACIÓN COMPLETA: Sistema restaurado con {running_count}/{initial_pod_count} pods Running"
+                )
+                recovery_complete = True
+
+            time.sleep(1)
+
+        elapsed_time = int(time.time() - start_time)
+        print(f" Monitoreo completado: {elapsed_time}s transcurridos")
+
+        if not recovery_started:
+            final_pods = self.get_pods(verbose=False)
+            final_running = len([p for p in final_pods if p["status"] == "Running"])
+            if final_running >= initial_pod_count:
+                self.generate_alert(
+                    f"RECUPERACIÓN DETECTADA: Sistema con {final_running} pods Running"
+                )
+
+        return problem_detected
+
+    def generate_report(self):
+        report_file = "scripts/chaos_test/reports/chaos_testing_report.json"
+
+        report = {
+            "chaos_test_summary": {
+                "namespace": self.namespace,
+                "target_selector": f"pod={self.pod_selector}",
+                "total_alerts": len(self.alerts),
+                "test_completed": True,
+            },
+            "alerts_generated": self.alerts,
+        }
+
+        with open(report_file, "w", encoding="utf-8") as f:
+            json.dump(report, f, indent=2, ensure_ascii=False)
+
+        print(f" REPORTE GENERADO: {report_file}")
+        return report_file
+
+
+def main():
+    print(" CHAOS TESTING MINIMAL")
+
+    chaos = MinimalChaosTest(namespace="default", pod_selector="timeserver-pod")
+
+    eliminated_pod = chaos.simulate_pod_deletion()
+
+    if eliminated_pod:
+        chaos.detect_problem(eliminated_pod, monitoring_duration=30)
+
+        report_file = chaos.generate_report()
+
+        print("\n" + "=" * 50)
+        print("CHAOS TESTING COMPLETADO")
+        print("=" * 50)
+        print(f" Total de alertas generadas: {len(chaos.alerts)}")
+        print(f" Reporte guardado en: {report_file}")
+
+        print("\n ALERTAS GENERADAS:")
+        for i, alert in enumerate(chaos.alerts, 1):
+            print(f"{i}. {alert['message']}")
+
+    else:
+        print(" Chaos testing falló en la eliminación del pod")
+
+
+if __name__ == "__main__":
+    main()
diff --git a/scripts/chaos_test/imgs/1.png b/scripts/chaos_test/imgs/1.png
new file mode 100644
index 0000000..cddd4b9
Binary files /dev/null and b/scripts/chaos_test/imgs/1.png differ
diff --git a/scripts/chaos_test/imgs/2.png b/scripts/chaos_test/imgs/2.png
new file mode 100644
index 0000000..e871d1d
Binary files /dev/null and b/scripts/chaos_test/imgs/2.png differ
diff --git a/scripts/chaos_test/imgs/3.png b/scripts/chaos_test/imgs/3.png
new file mode 100644
index 0000000..b38d28c
Binary files /dev/null and b/scripts/chaos_test/imgs/3.png differ
diff --git a/scripts/chaos_test/imgs/4.png b/scripts/chaos_test/imgs/4.png
new file mode 100644
index 0000000..34a2d0e
Binary files /dev/null and b/scripts/chaos_test/imgs/4.png differ
diff --git a/scripts/chaos_test/imgs/5.png b/scripts/chaos_test/imgs/5.png
new file mode 100644
index 0000000..a0e4db3
Binary files /dev/null and b/scripts/chaos_test/imgs/5.png differ

commit b41520231a10316c5c2f82ba885772c7dc8c39bb
Author: Chriss5-2 <christiangiovannixd@gmail.com>
Date:   Mon Jun 30 00:31:23 2025 -0500

    feat(py): Implementando funcionamiento de gestión de alertar en nuestro visualizar de métricas
---
 scripts/metric_collector/README-visualizer.md |  6 +-
 scripts/metric_collector/metric_visualizer.py | 83 +++++++++++++++++++++++++++
 2 files changed, 88 insertions(+), 1 deletion(-)

diff --git a/scripts/metric_collector/README-visualizer.md b/scripts/metric_collector/README-visualizer.md
index 0251228..a299ea5 100644
--- a/scripts/metric_collector/README-visualizer.md
+++ b/scripts/metric_collector/README-visualizer.md
@@ -87,4 +87,8 @@ Esta función se encargará de leer el archivo `csv` creado y de acuerdo a esto,
 El objetivo de esta función es para cumplir con el primer requisito de la rúbrica para esta tarea, la cuál es de mostrar los datos en la consola pero de manera ordenada y simple, así que con la libreria tabulate, lo que realicé fue mostrar todos los datos de manera tabulada en la pantalla, haciendo que sea más entendible y fácil de leer al momento de ejecutar el script
 
 ## Funcion generate_html_graph
-Esta función termina de cumplir el último objetivo de la tarea, la cuál es generar un archivo `html` donde sea posible su visualización, en un primer momento lo quise realizar de manera vertical, pero luego como hay una gran diferencia entre los datos de las columnas, había perdida de datos o mejor dicho, no se podía ver correctamente algunas barras, así que para esta función lo que hice fue que los gráficos de barras se muestren de manera horizontal, ya que así tendrá más tamaño y podrá verse el gráfico correctamente con todas las columnas que presentan los archivos `csv`
\ No newline at end of file
+Esta función termina de cumplir el último objetivo de la tarea, la cuál es generar un archivo `html` donde sea posible su visualización, en un primer momento lo quise realizar de manera vertical, pero luego como hay una gran diferencia entre los datos de las columnas, había perdida de datos o mejor dicho, no se podía ver correctamente algunas barras, así que para esta función lo que hice fue que los gráficos de barras se muestren de manera horizontal, ya que así tendrá más tamaño y podrá verse el gráfico correctamente con todas las columnas que presentan los archivos `csv`
+
+# Ejecución
+
+La forma de ejecutar es primero correr el programa `metric_collector.py` y luego `metric_visualizer.py` ya que el último script lee los archvos que se crearon con  `metric_collector.py`
\ No newline at end of file
diff --git a/scripts/metric_collector/metric_visualizer.py b/scripts/metric_collector/metric_visualizer.py
index e627863..0966ce8 100644
--- a/scripts/metric_collector/metric_visualizer.py
+++ b/scripts/metric_collector/metric_visualizer.py
@@ -5,6 +5,9 @@ import subprocess
 import pandas as pd
 from tabulate import tabulate
 import plotly.express as px
+import json
+from datetime import datetime
+
 
 # Comandos para obtener métricas de pods y nodes
 # 1.- kubectl top pods -n <namespace>
@@ -30,6 +33,20 @@ metrics_dir = root_dir / "metrics"
 metrics_dir.mkdir(exist_ok=True)
 
 
+def get_namespaces():
+    namespaces = subprocess.run(
+        ["kubectl", "get", "namespaces", "-o", "name"],
+        capture_output=True,
+        text=True,
+        check=True,
+    )
+    all_namespaces = [
+        line.replace("namespace/", "")
+        for line in namespaces.stdout.strip().splitlines()
+    ]
+    return all_namespaces
+
+
 # Visualización de métricas
 def clean_raw_metrics_pods(pod_path):
     df = pd.read_csv(pod_path, sep=r'\s+')
@@ -130,8 +147,74 @@ def generate_html_graph_nodes(df, output_path, name):
     print(f"\nGráfico HTML guardado en: {name}")
 
 
+def check_umbral(path, kind):
+    df = pd.read_csv(path, sep=r'\s+')
+
+    umbral_cpu = 10
+
+    def convertir_cpu(cpu_str):
+        if isinstance(cpu_str, str) and cpu_str.endswith("m"):
+            return int(cpu_str[:-1])
+        return 0
+
+    df['CPU_m'] = df['CPU(cores)'].apply(convertir_cpu)
+
+    for index, row in df.iterrows():
+        if row['CPU_m'] > umbral_cpu:
+            print(f"Alerta: El {kind} {row['NAME']} está usando {row['CPU_m']}m de CPU (>{umbral_cpu}m)")
+
+
+def alert_umbral():
+    path = metrics_dir
+    folders = os.listdir(path)
+    for folder in folders:
+        files_path = path / folder
+        files = os.listdir(files_path)
+        for file in files:
+            if file.endswith(".csv"):
+                with open(files_path / file, "r", encoding="utf-8") as f:
+                    read = f.read()
+                if read:
+                    check_umbral(files_path / file, kind=folder)
+
+
+def alert_pods_not_ready(namespaces):
+    for ns in namespaces:
+        try:
+            result = subprocess.run(
+                ["kubectl", "get", "pods", "-n", ns, "-o", "json"],
+                capture_output=True,
+                text=True,
+                check=True
+            )
+            pods_json = json.loads(result.stdout)
+
+            for pod in pods_json["items"]:
+                pod_name = pod["metadata"]["name"]
+                conditions = pod.get("status", {}).get("conditions", [])
+                ready_condition = next((c for c in conditions if c["type"] == "Ready"), None)
+
+                if ready_condition and ready_condition["status"] != "True":
+                    # Modificar el status a False para verificar que funciona
+                    last_transition = ready_condition.get("lastTransitionTime")
+                    if last_transition:
+                        dt = datetime.strptime(last_transition, "%Y-%m-%dT%H:%M:%SZ")
+                        now = datetime.utcnow()
+                        duration = now - dt
+                        if duration.total_seconds() > 300:  # > 5 minutos
+                            print(f"⚠️ Alerta: El pod '{pod_name}' en el namespace '{ns}' no está Ready desde hace más de 5 minutos.")
+                        else:
+                            print(f"⚠️ El pod '{pod_name}' en el namespace '{ns}' no está Ready (desde {last_transition})")
+                    else:
+                        print(f"⚠️ El pod '{pod_name}' en el namespace '{ns}' no está Ready (sin timestamp)")
+        except subprocess.CalledProcessError as e:
+            print(f"Error al obtener estado de pods en el namespace {ns}: {e.stderr}")
+
+
 def main():
     visualize_metrics_console()
+    alert_umbral()
+    alert_pods_not_ready(get_namespaces())
 
 
 if __name__ == "__main__":

commit d24afa7673bc7259319e7d3a49628d6bd2790e9e
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Mon Jun 30 00:36:03 2025 -0500

    test(py): agrega fixtures para tests de alertas
---
 tests/conftest.py | 36 ++++++++++++++++++++++++++++++++++--
 1 file changed, 34 insertions(+), 2 deletions(-)

diff --git a/tests/conftest.py b/tests/conftest.py
index 1976ca9..9f72d09 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -2,6 +2,10 @@ import pytest
 from kubernetes import config, client
 import shutil
 from pathlib import Path
+from scripts.metric_collector import metric_collector
+from scripts.log_collector import log_collector
+from scripts.metric_collector import metric_visualizer
+import pandas as pd
 
 NAMESPACE = "default"
 DEPLOYMENT_NAME = "timeserver"
@@ -97,7 +101,6 @@ def observability_dirs(project_root):
 
 @pytest.fixture(scope="function")
 def run_metric_collector(observability_dirs):
-    from scripts.metric_collector import metric_collector
     try:
         metric_collector.main()
         return observability_dirs["metrics"]
@@ -107,7 +110,6 @@ def run_metric_collector(observability_dirs):
 
 @pytest.fixture(scope="function")
 def run_log_collector(observability_dirs, timeserver_pods):
-    from scripts.log_collector import log_collector
     if not timeserver_pods:
         pytest.skip("No se encontraron pods para la recoleccion de logs.")
 
@@ -117,3 +119,33 @@ def run_log_collector(observability_dirs, timeserver_pods):
         return observability_dirs["logs"]
     except Exception as e:
         pytest.fail(f"La recoleccion de logs fallo: {e}")
+
+
+@pytest.fixture(scope="function")
+def run_metric_visualizer(run_metric_collector):
+    try:
+        metric_visualizer.main()
+        return run_metric_collector
+    except Exception as e:
+        pytest.fail(f"La visualización de métricas falló: {e}")
+
+
+@pytest.fixture
+def mock_metrics_dir(tmp_path):
+    metrics_path = tmp_path / "metrics"
+    pods_path = metrics_path / "pods"
+    pods_path.mkdir(parents=True)
+
+    pd.DataFrame({
+        'NAME': ['pod-1'],
+        'CPU(cores)': ['5m'],
+        'MEMORY(bytes)': ['10Mi']
+    }).to_csv(pods_path / "normal_metrics.csv", sep='\t', index=False)
+
+    pd.DataFrame({
+        'NAME': ['pod-2'],
+        'CPU(cores)': ['15m'],
+        'MEMORY(bytes)': ['20Mi']
+    }).to_csv(pods_path / "alert_metrics.csv", sep='\t', index=False)
+
+    return metrics_path

commit fba8d1c4cc7bc6d55cb1aadf3cd72c504b04a12a
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Mon Jun 30 00:36:53 2025 -0500

    fix(py): fix creacion de dirs en tests de metricas
---
 tests/test_metric_visualizer.py | 11 ++---------
 1 file changed, 2 insertions(+), 9 deletions(-)

diff --git a/tests/test_metric_visualizer.py b/tests/test_metric_visualizer.py
index 21fbb90..df49019 100644
--- a/tests/test_metric_visualizer.py
+++ b/tests/test_metric_visualizer.py
@@ -1,18 +1,11 @@
 import pytest
-from scripts.metric_collector import metric_collector
+from pathlib import Path
 from scripts.metric_collector import metric_visualizer
 
 
 root_dir = metric_visualizer.find_root_dir("Proyecto7-PC4")
 
 
-def setup_module(module):
-    # Se ejecuta una vez antes de cualquier test en este archivo
-    print("\n[setup] Ejecutando dependencias...")
-    metric_collector.main()  # si aplica
-    metric_visualizer.main()  # o alguna función que prepare el entorno
-
-
 @pytest.mark.xfail(reason="El directorio no existe")
 def test_not_fing_root_dir():
     assert metric_visualizer.find_root_dir("non_existent_dir")
@@ -22,7 +15,7 @@ def test_find_root_dir():
     root = metric_visualizer.find_root_dir("Proyecto7-PC4")
     assert root.is_dir()
 
-
+@pytest.mark.xfail(reason="El directorio no existe")
 def test_clean_raw_metrics_pods():
     pod_path = root_dir / "metrics" / "pods" / "default_metrics.csv"
     df = metric_visualizer.clean_raw_metrics_pods(pod_path)

commit ad75340a0284622a2fb4969109002f2018b7df18
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Mon Jun 30 00:37:09 2025 -0500

    test(py): agrega test para visualizer de metricas
---
 tests/test_e2e.py | 83 +++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 83 insertions(+)

diff --git a/tests/test_e2e.py b/tests/test_e2e.py
index e3538b6..6ab0ef9 100644
--- a/tests/test_e2e.py
+++ b/tests/test_e2e.py
@@ -1,3 +1,6 @@
+from unittest.mock import patch, MagicMock
+from scripts.metric_collector import metric_visualizer
+
 def test_metric_dirs(run_metric_collector):
     metrics_dir = run_metric_collector
     assert metrics_dir.exists(), "El directorio principal de métricas no fue creado."
@@ -37,3 +40,83 @@ def test_log_not_empty(run_log_collector):
 
     assert len(content) > 0, "El archivo de logs principal está vacío."
     assert "Logs del pod:" in content, "El formato esperado no se encontró en el log."
+
+
+def test_html_graphs_generated(run_metric_visualizer):
+    metrics_dir = run_metric_visualizer
+    html_files = list(metrics_dir.rglob("*.html"))
+    assert len(html_files) > 0, "No se genero HTML archivo"
+
+
+def test_html_graphs_not_empty(run_metric_visualizer):
+    metrics_dir = run_metric_visualizer
+    html_files = list(metrics_dir.rglob("*.html"))
+
+    for html_file in html_files:
+        with open(html_file, 'r', encoding='utf-8') as f:
+            content = f.read()
+        assert len(content) > 0, f"El archivo HTML {html_file} esta vacío."
+        assert "<html>" in content, f"El archivo {html_file} no es un HTML valido."
+
+def test_alert_umbral(monkeypatch, capsys, mock_metrics_dir):
+    monkeypatch.setattr(metric_visualizer, 'metrics_dir', mock_metrics_dir)
+    metric_visualizer.alert_umbral()
+    captured = capsys.readouterr()
+    assert "15m de CPU" in captured.out
+    assert "pod-1" not in captured.out
+
+
+@patch('subprocess.run')
+def test_alert_pods_not_ready(mock_subprocess_run, capsys):
+    not_ready_pod_json = '''
+    {
+        "items": [
+            {
+                "metadata": {
+                    "name": "test-pod-not-ready"
+                },
+                "status": {
+                    "conditions": [
+                        {
+                            "type": "Ready",
+                            "status": "False",
+                            "lastTransitionTime": "2025-01-01T12:00:00Z"
+                        }
+                    ]
+                }
+            }
+        ]
+    }
+    '''
+
+    ready_pod_json = '''
+    {
+        "items": [
+            {
+                "metadata": {
+                    "name": "test-pod-ready"
+                },
+                "status": {
+                    "conditions": [
+                        {
+                            "type": "Ready",
+                            "status": "True"
+                        }
+                    ]
+                }
+            }
+        ]
+    }
+    '''
+
+    mock_subprocess_run.side_effect = [
+        MagicMock(stdout=not_ready_pod_json, check_return_value=None),
+        MagicMock(stdout=ready_pod_json, check_return_value=None)
+    ]
+
+    namespaces = ["ns1", "ns2"]
+    metric_visualizer.alert_pods_not_ready(namespaces)
+
+    captured = capsys.readouterr()
+    assert "no está Ready" in captured.out
+    assert "test-pod-ready" not in captured.out

commit 3a04144e29a335c97388569849da675eeeeedcc2
Author: Alex Vega <axvg@users.noreply.github.com>
Date:   Mon Jun 30 00:37:31 2025 -0500

    test(ini): agrega configuracion para pytest
---
 pytest.ini | 11 ++++++++++-
 1 file changed, 10 insertions(+), 1 deletion(-)

diff --git a/pytest.ini b/pytest.ini
index 03f586d..1ddd7f5 100644
--- a/pytest.ini
+++ b/pytest.ini
@@ -1,2 +1,11 @@
 [pytest]
-pythonpath = .
\ No newline at end of file
+pythonpath = .
+addopts = --cov=scripts --cov-report=term-missing --cov-report=html --cov-fail-under=80 -vv
+filterwarnings =
+    ignore::DeprecationWarning
+
+[coverage:run]
+source = scripts
+omit =
+    tests/*
+    */tests/*
\ No newline at end of file

commit ef4fc39ab025290d8c6f6da346c21994f8c3e745
Merge: 35b3919 3a04144
Author: Jesus Diego Osorio Tello <130506742+JesusOsorio-19@users.noreply.github.com>
Date:   Mon Jun 30 00:57:55 2025 -0500

    Merge pull request #24 from grupo10-CC3S2/tests/health-e2e-tests
    
    Tests/health e2e tests

commit 5fdc70f4925bde87ed03222ab6e2253acbf3f04f
Merge: ef4fc39 3e85acd
Author: Alex Vega <91773368+axvg@users.noreply.github.com>
Date:   Mon Jun 30 00:58:59 2025 -0500

    Merge pull request #25 from grupo10-CC3S2/feature/script/chaos-test
    
    Chaos_testing implementado

commit a31c3f569e75e3d9ade2f6e32f14187bf7443a74
Merge: 5fdc70f b415202
Author: Jesus Diego Osorio Tello <130506742+JesusOsorio-19@users.noreply.github.com>
Date:   Mon Jun 30 01:08:38 2025 -0500

    Merge pull request #26 from grupo10-CC3S2/feature/scripts/alertas
    
    Implementación de gestor de alertas según las métricas

commit a30139408a8e60eff9383d2d71e66c7a824afcce
Author: Diego <jesustello192002@gmail.com>
Date:   Mon Jun 30 01:57:22 2025 -0500

    docs(md): Añade video de sprint 3 y video final de la Pc4
---
 videos/README.md | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/videos/README.md b/videos/README.md
index 7dfa9e4..818ccf9 100644
--- a/videos/README.md
+++ b/videos/README.md
@@ -13,3 +13,12 @@
 ## Sprint-2
 
 [Video Sprint 2](https://drive.google.com/file/d/14Z8FHLXlaGn3w7PuGp_7PCWK98kEiZxH/view?usp=drive_link)
+
+## Sprint-3
+
+[Video Sprint 3](https://drive.google.com/file/d/1fPwY-5F4EgSsXc3boFFFUw49nAGsQU9E/view?usp=drive_linkk)
+
+
+## Video final
+
+[Video Final](https://drive.google.com/file/d/1xdrc_mWNptTCqXFrfD85dxDXP5_fbjHU/view?usp=drive_link)
\ No newline at end of file

commit 70c938508151caf5e1f01693b973a5e313fd345f
Merge: ccc1795 a301394
Author: Christian Luna Jaramillo <65150753+Chriss5-2@users.noreply.github.com>
Date:   Mon Jun 30 02:03:21 2025 -0500

    Merge pull request #27 from grupo10-CC3S2/develop
    
    Pull Request Final
